{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD_RSER5Lkb5"
      },
      "source": [
        "# Homework solution PyTorch Diabetes\n",
        "\n",
        "https://www.kaggle.com/uciml/pima-indians-diabetes-database/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tP2BcEILoLB"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b85d_o8BdFub",
        "outputId": "e597334f-0bc7-40a0-cb8e-b35cc975c449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.5.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1WlABbCcw2B"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFSnAUTVQN2j"
      },
      "source": [
        "diabetes = pd.read_csv('diabetes.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIoAdvbMuaUD",
        "outputId": "a1e47aed-6aef-4e65-bec8-83842e1a37c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "diabetes.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2L0Zo3oQg66",
        "outputId": "0d683573-265c-4e6e-9233-a741e938cd2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inputs = diabetes.iloc[:, 0:8].values\n",
        "inputs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw6crTDBfaLl",
        "outputId": "2c5afa9b-04f0-49ad-c891-c1e114111163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKVjNkwkumY7"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "inputs = scaler.fit_transform(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk9mvY2AuvJq",
        "outputId": "72efda5f-3d7d-440c-c725-edf1d954db6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwoclkDjQq-6",
        "outputId": "4cca80ff-e695-4ff6-89ec-ef1d61e2aa6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "outputs = diabetes.iloc[:,8].values\n",
        "outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX9ZDhUMgBsv"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size = 0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SEVQyX9gR4O",
        "outputId": "ce60e815-ef9a-417a-9eea-b63f13072fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(614, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKyN_plmgZzH",
        "outputId": "a4805637-1a73-4466-8037-db0624e3b031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(154, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72uvlxJrOuWd"
      },
      "source": [
        "## Data transformation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk5Gjgb7hBCo",
        "outputId": "dc0934b0-6fff-4942-ea7e-816472890a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqPER9AYhTpt"
      },
      "source": [
        "X_train = torch.tensor(X_train, dtype=torch.float)\n",
        "y_train = torch.tensor(y_train, dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-2HrvEJh5Km",
        "outputId": "66c1e3fd-af84-4323-d082-fb0ced4fb5aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__6a-iZhiJVI"
      },
      "source": [
        "dataset = torch.utils.data.TensorDataset(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0sP_kvViZJl",
        "outputId": "53ac24c7-2878-4f1f-a8ea-3a3aa2b48e99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataset.TensorDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dIWzA4wihKD"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGDLesyDQpIb"
      },
      "source": [
        "## Neural network structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaSPjUFhatlQ",
        "outputId": "be57a979-fed3-4369-a09c-5e39644a738d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(8 + 1) / 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FAFgY56jmdG"
      },
      "source": [
        "# 8 -> 5 -> 5 -> 1\n",
        "network = nn.Sequential(nn.Linear(8, 5),\n",
        "                          nn.Sigmoid(),\n",
        "                          nn.Linear(5, 5),\n",
        "                          nn.Sigmoid(),\n",
        "                          nn.Linear(5, 1),\n",
        "                          nn.Sigmoid())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixwI_mhZlDVW",
        "outputId": "18d91739-62e5-4a38-d68b-bfd5e4d4cb04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "network.parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Sequential(\n",
              "  (0): Linear(in_features=8, out_features=5, bias=True)\n",
              "  (1): Sigmoid()\n",
              "  (2): Linear(in_features=5, out_features=5, bias=True)\n",
              "  (3): Sigmoid()\n",
              "  (4): Linear(in_features=5, out_features=1, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--bNcvlplMh9"
      },
      "source": [
        "loss_function = nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um6Tr3s_lXHK"
      },
      "source": [
        "optimizer = torch.optim.Adam(network.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exieZFSam_eI",
        "outputId": "e8b67433-835f-4087-e2d0-aedea5216b21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 2000\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0.\n",
        "\n",
        "  for data in train_loader:\n",
        "    inputs, outputs = data\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions = network.forward(inputs)\n",
        "    loss = loss_function(predictions, outputs)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  print('Epoch %3d: loss %.5f' % (epoch+1, running_loss/len(train_loader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch   1: loss 0.66394\n",
            "Epoch   2: loss 0.64807\n",
            "Epoch   3: loss 0.64290\n",
            "Epoch   4: loss 0.63505\n",
            "Epoch   5: loss 0.62313\n",
            "Epoch   6: loss 0.60549\n",
            "Epoch   7: loss 0.58290\n",
            "Epoch   8: loss 0.56031\n",
            "Epoch   9: loss 0.54233\n",
            "Epoch  10: loss 0.52902\n",
            "Epoch  11: loss 0.51870\n",
            "Epoch  12: loss 0.51023\n",
            "Epoch  13: loss 0.50305\n",
            "Epoch  14: loss 0.49684\n",
            "Epoch  15: loss 0.49144\n",
            "Epoch  16: loss 0.48672\n",
            "Epoch  17: loss 0.48261\n",
            "Epoch  18: loss 0.47905\n",
            "Epoch  19: loss 0.47596\n",
            "Epoch  20: loss 0.47328\n",
            "Epoch  21: loss 0.47091\n",
            "Epoch  22: loss 0.46880\n",
            "Epoch  23: loss 0.46689\n",
            "Epoch  24: loss 0.46514\n",
            "Epoch  25: loss 0.46354\n",
            "Epoch  26: loss 0.46205\n",
            "Epoch  27: loss 0.46068\n",
            "Epoch  28: loss 0.45941\n",
            "Epoch  29: loss 0.45824\n",
            "Epoch  30: loss 0.45717\n",
            "Epoch  31: loss 0.45618\n",
            "Epoch  32: loss 0.45528\n",
            "Epoch  33: loss 0.45446\n",
            "Epoch  34: loss 0.45372\n",
            "Epoch  35: loss 0.45305\n",
            "Epoch  36: loss 0.45245\n",
            "Epoch  37: loss 0.45190\n",
            "Epoch  38: loss 0.45141\n",
            "Epoch  39: loss 0.45097\n",
            "Epoch  40: loss 0.45057\n",
            "Epoch  41: loss 0.45021\n",
            "Epoch  42: loss 0.44989\n",
            "Epoch  43: loss 0.44959\n",
            "Epoch  44: loss 0.44932\n",
            "Epoch  45: loss 0.44908\n",
            "Epoch  46: loss 0.44886\n",
            "Epoch  47: loss 0.44866\n",
            "Epoch  48: loss 0.44847\n",
            "Epoch  49: loss 0.44830\n",
            "Epoch  50: loss 0.44814\n",
            "Epoch  51: loss 0.44799\n",
            "Epoch  52: loss 0.44786\n",
            "Epoch  53: loss 0.44773\n",
            "Epoch  54: loss 0.44761\n",
            "Epoch  55: loss 0.44750\n",
            "Epoch  56: loss 0.44739\n",
            "Epoch  57: loss 0.44729\n",
            "Epoch  58: loss 0.44720\n",
            "Epoch  59: loss 0.44711\n",
            "Epoch  60: loss 0.44703\n",
            "Epoch  61: loss 0.44695\n",
            "Epoch  62: loss 0.44687\n",
            "Epoch  63: loss 0.44680\n",
            "Epoch  64: loss 0.44673\n",
            "Epoch  65: loss 0.44666\n",
            "Epoch  66: loss 0.44660\n",
            "Epoch  67: loss 0.44653\n",
            "Epoch  68: loss 0.44647\n",
            "Epoch  69: loss 0.44642\n",
            "Epoch  70: loss 0.44636\n",
            "Epoch  71: loss 0.44631\n",
            "Epoch  72: loss 0.44625\n",
            "Epoch  73: loss 0.44620\n",
            "Epoch  74: loss 0.44615\n",
            "Epoch  75: loss 0.44611\n",
            "Epoch  76: loss 0.44606\n",
            "Epoch  77: loss 0.44601\n",
            "Epoch  78: loss 0.44597\n",
            "Epoch  79: loss 0.44592\n",
            "Epoch  80: loss 0.44588\n",
            "Epoch  81: loss 0.44584\n",
            "Epoch  82: loss 0.44580\n",
            "Epoch  83: loss 0.44575\n",
            "Epoch  84: loss 0.44571\n",
            "Epoch  85: loss 0.44567\n",
            "Epoch  86: loss 0.44564\n",
            "Epoch  87: loss 0.44560\n",
            "Epoch  88: loss 0.44556\n",
            "Epoch  89: loss 0.44552\n",
            "Epoch  90: loss 0.44548\n",
            "Epoch  91: loss 0.44545\n",
            "Epoch  92: loss 0.44541\n",
            "Epoch  93: loss 0.44537\n",
            "Epoch  94: loss 0.44533\n",
            "Epoch  95: loss 0.44530\n",
            "Epoch  96: loss 0.44526\n",
            "Epoch  97: loss 0.44522\n",
            "Epoch  98: loss 0.44519\n",
            "Epoch  99: loss 0.44515\n",
            "Epoch 100: loss 0.44511\n",
            "Epoch 101: loss 0.44508\n",
            "Epoch 102: loss 0.44504\n",
            "Epoch 103: loss 0.44500\n",
            "Epoch 104: loss 0.44496\n",
            "Epoch 105: loss 0.44492\n",
            "Epoch 106: loss 0.44489\n",
            "Epoch 107: loss 0.44485\n",
            "Epoch 108: loss 0.44481\n",
            "Epoch 109: loss 0.44477\n",
            "Epoch 110: loss 0.44472\n",
            "Epoch 111: loss 0.44468\n",
            "Epoch 112: loss 0.44464\n",
            "Epoch 113: loss 0.44460\n",
            "Epoch 114: loss 0.44455\n",
            "Epoch 115: loss 0.44451\n",
            "Epoch 116: loss 0.44446\n",
            "Epoch 117: loss 0.44442\n",
            "Epoch 118: loss 0.44437\n",
            "Epoch 119: loss 0.44432\n",
            "Epoch 120: loss 0.44427\n",
            "Epoch 121: loss 0.44422\n",
            "Epoch 122: loss 0.44416\n",
            "Epoch 123: loss 0.44411\n",
            "Epoch 124: loss 0.44406\n",
            "Epoch 125: loss 0.44400\n",
            "Epoch 126: loss 0.44394\n",
            "Epoch 127: loss 0.44388\n",
            "Epoch 128: loss 0.44382\n",
            "Epoch 129: loss 0.44376\n",
            "Epoch 130: loss 0.44370\n",
            "Epoch 131: loss 0.44363\n",
            "Epoch 132: loss 0.44357\n",
            "Epoch 133: loss 0.44350\n",
            "Epoch 134: loss 0.44343\n",
            "Epoch 135: loss 0.44336\n",
            "Epoch 136: loss 0.44329\n",
            "Epoch 137: loss 0.44321\n",
            "Epoch 138: loss 0.44314\n",
            "Epoch 139: loss 0.44306\n",
            "Epoch 140: loss 0.44298\n",
            "Epoch 141: loss 0.44291\n",
            "Epoch 142: loss 0.44282\n",
            "Epoch 143: loss 0.44274\n",
            "Epoch 144: loss 0.44266\n",
            "Epoch 145: loss 0.44258\n",
            "Epoch 146: loss 0.44249\n",
            "Epoch 147: loss 0.44240\n",
            "Epoch 148: loss 0.44232\n",
            "Epoch 149: loss 0.44223\n",
            "Epoch 150: loss 0.44214\n",
            "Epoch 151: loss 0.44205\n",
            "Epoch 152: loss 0.44195\n",
            "Epoch 153: loss 0.44186\n",
            "Epoch 154: loss 0.44176\n",
            "Epoch 155: loss 0.44166\n",
            "Epoch 156: loss 0.44157\n",
            "Epoch 157: loss 0.44147\n",
            "Epoch 158: loss 0.44136\n",
            "Epoch 159: loss 0.44126\n",
            "Epoch 160: loss 0.44116\n",
            "Epoch 161: loss 0.44105\n",
            "Epoch 162: loss 0.44094\n",
            "Epoch 163: loss 0.44083\n",
            "Epoch 164: loss 0.44072\n",
            "Epoch 165: loss 0.44061\n",
            "Epoch 166: loss 0.44050\n",
            "Epoch 167: loss 0.44038\n",
            "Epoch 168: loss 0.44026\n",
            "Epoch 169: loss 0.44014\n",
            "Epoch 170: loss 0.44002\n",
            "Epoch 171: loss 0.43990\n",
            "Epoch 172: loss 0.43978\n",
            "Epoch 173: loss 0.43965\n",
            "Epoch 174: loss 0.43952\n",
            "Epoch 175: loss 0.43939\n",
            "Epoch 176: loss 0.43926\n",
            "Epoch 177: loss 0.43913\n",
            "Epoch 178: loss 0.43899\n",
            "Epoch 179: loss 0.43886\n",
            "Epoch 180: loss 0.43872\n",
            "Epoch 181: loss 0.43858\n",
            "Epoch 182: loss 0.43844\n",
            "Epoch 183: loss 0.43830\n",
            "Epoch 184: loss 0.43815\n",
            "Epoch 185: loss 0.43801\n",
            "Epoch 186: loss 0.43786\n",
            "Epoch 187: loss 0.43771\n",
            "Epoch 188: loss 0.43756\n",
            "Epoch 189: loss 0.43741\n",
            "Epoch 190: loss 0.43726\n",
            "Epoch 191: loss 0.43711\n",
            "Epoch 192: loss 0.43695\n",
            "Epoch 193: loss 0.43680\n",
            "Epoch 194: loss 0.43664\n",
            "Epoch 195: loss 0.43649\n",
            "Epoch 196: loss 0.43633\n",
            "Epoch 197: loss 0.43618\n",
            "Epoch 198: loss 0.43602\n",
            "Epoch 199: loss 0.43586\n",
            "Epoch 200: loss 0.43571\n",
            "Epoch 201: loss 0.43555\n",
            "Epoch 202: loss 0.43539\n",
            "Epoch 203: loss 0.43524\n",
            "Epoch 204: loss 0.43508\n",
            "Epoch 205: loss 0.43493\n",
            "Epoch 206: loss 0.43477\n",
            "Epoch 207: loss 0.43462\n",
            "Epoch 208: loss 0.43447\n",
            "Epoch 209: loss 0.43432\n",
            "Epoch 210: loss 0.43417\n",
            "Epoch 211: loss 0.43402\n",
            "Epoch 212: loss 0.43387\n",
            "Epoch 213: loss 0.43372\n",
            "Epoch 214: loss 0.43357\n",
            "Epoch 215: loss 0.43343\n",
            "Epoch 216: loss 0.43328\n",
            "Epoch 217: loss 0.43314\n",
            "Epoch 218: loss 0.43300\n",
            "Epoch 219: loss 0.43286\n",
            "Epoch 220: loss 0.43272\n",
            "Epoch 221: loss 0.43258\n",
            "Epoch 222: loss 0.43244\n",
            "Epoch 223: loss 0.43230\n",
            "Epoch 224: loss 0.43217\n",
            "Epoch 225: loss 0.43203\n",
            "Epoch 226: loss 0.43190\n",
            "Epoch 227: loss 0.43177\n",
            "Epoch 228: loss 0.43164\n",
            "Epoch 229: loss 0.43151\n",
            "Epoch 230: loss 0.43138\n",
            "Epoch 231: loss 0.43125\n",
            "Epoch 232: loss 0.43113\n",
            "Epoch 233: loss 0.43100\n",
            "Epoch 234: loss 0.43088\n",
            "Epoch 235: loss 0.43075\n",
            "Epoch 236: loss 0.43063\n",
            "Epoch 237: loss 0.43051\n",
            "Epoch 238: loss 0.43038\n",
            "Epoch 239: loss 0.43026\n",
            "Epoch 240: loss 0.43014\n",
            "Epoch 241: loss 0.43002\n",
            "Epoch 242: loss 0.42990\n",
            "Epoch 243: loss 0.42979\n",
            "Epoch 244: loss 0.42967\n",
            "Epoch 245: loss 0.42955\n",
            "Epoch 246: loss 0.42944\n",
            "Epoch 247: loss 0.42932\n",
            "Epoch 248: loss 0.42920\n",
            "Epoch 249: loss 0.42909\n",
            "Epoch 250: loss 0.42897\n",
            "Epoch 251: loss 0.42886\n",
            "Epoch 252: loss 0.42875\n",
            "Epoch 253: loss 0.42863\n",
            "Epoch 254: loss 0.42852\n",
            "Epoch 255: loss 0.42841\n",
            "Epoch 256: loss 0.42829\n",
            "Epoch 257: loss 0.42818\n",
            "Epoch 258: loss 0.42807\n",
            "Epoch 259: loss 0.42796\n",
            "Epoch 260: loss 0.42785\n",
            "Epoch 261: loss 0.42774\n",
            "Epoch 262: loss 0.42763\n",
            "Epoch 263: loss 0.42752\n",
            "Epoch 264: loss 0.42741\n",
            "Epoch 265: loss 0.42730\n",
            "Epoch 266: loss 0.42719\n",
            "Epoch 267: loss 0.42708\n",
            "Epoch 268: loss 0.42697\n",
            "Epoch 269: loss 0.42686\n",
            "Epoch 270: loss 0.42676\n",
            "Epoch 271: loss 0.42665\n",
            "Epoch 272: loss 0.42654\n",
            "Epoch 273: loss 0.42644\n",
            "Epoch 274: loss 0.42633\n",
            "Epoch 275: loss 0.42623\n",
            "Epoch 276: loss 0.42612\n",
            "Epoch 277: loss 0.42602\n",
            "Epoch 278: loss 0.42592\n",
            "Epoch 279: loss 0.42582\n",
            "Epoch 280: loss 0.42571\n",
            "Epoch 281: loss 0.42561\n",
            "Epoch 282: loss 0.42551\n",
            "Epoch 283: loss 0.42541\n",
            "Epoch 284: loss 0.42531\n",
            "Epoch 285: loss 0.42522\n",
            "Epoch 286: loss 0.42512\n",
            "Epoch 287: loss 0.42502\n",
            "Epoch 288: loss 0.42492\n",
            "Epoch 289: loss 0.42483\n",
            "Epoch 290: loss 0.42473\n",
            "Epoch 291: loss 0.42464\n",
            "Epoch 292: loss 0.42455\n",
            "Epoch 293: loss 0.42445\n",
            "Epoch 294: loss 0.42436\n",
            "Epoch 295: loss 0.42427\n",
            "Epoch 296: loss 0.42418\n",
            "Epoch 297: loss 0.42409\n",
            "Epoch 298: loss 0.42400\n",
            "Epoch 299: loss 0.42391\n",
            "Epoch 300: loss 0.42382\n",
            "Epoch 301: loss 0.42374\n",
            "Epoch 302: loss 0.42365\n",
            "Epoch 303: loss 0.42357\n",
            "Epoch 304: loss 0.42348\n",
            "Epoch 305: loss 0.42340\n",
            "Epoch 306: loss 0.42331\n",
            "Epoch 307: loss 0.42323\n",
            "Epoch 308: loss 0.42315\n",
            "Epoch 309: loss 0.42307\n",
            "Epoch 310: loss 0.42299\n",
            "Epoch 311: loss 0.42291\n",
            "Epoch 312: loss 0.42283\n",
            "Epoch 313: loss 0.42275\n",
            "Epoch 314: loss 0.42267\n",
            "Epoch 315: loss 0.42259\n",
            "Epoch 316: loss 0.42252\n",
            "Epoch 317: loss 0.42244\n",
            "Epoch 318: loss 0.42237\n",
            "Epoch 319: loss 0.42229\n",
            "Epoch 320: loss 0.42222\n",
            "Epoch 321: loss 0.42215\n",
            "Epoch 322: loss 0.42207\n",
            "Epoch 323: loss 0.42200\n",
            "Epoch 324: loss 0.42193\n",
            "Epoch 325: loss 0.42186\n",
            "Epoch 326: loss 0.42179\n",
            "Epoch 327: loss 0.42172\n",
            "Epoch 328: loss 0.42165\n",
            "Epoch 329: loss 0.42158\n",
            "Epoch 330: loss 0.42151\n",
            "Epoch 331: loss 0.42145\n",
            "Epoch 332: loss 0.42138\n",
            "Epoch 333: loss 0.42131\n",
            "Epoch 334: loss 0.42125\n",
            "Epoch 335: loss 0.42118\n",
            "Epoch 336: loss 0.42112\n",
            "Epoch 337: loss 0.42106\n",
            "Epoch 338: loss 0.42099\n",
            "Epoch 339: loss 0.42093\n",
            "Epoch 340: loss 0.42087\n",
            "Epoch 341: loss 0.42081\n",
            "Epoch 342: loss 0.42074\n",
            "Epoch 343: loss 0.42068\n",
            "Epoch 344: loss 0.42062\n",
            "Epoch 345: loss 0.42056\n",
            "Epoch 346: loss 0.42050\n",
            "Epoch 347: loss 0.42045\n",
            "Epoch 348: loss 0.42039\n",
            "Epoch 349: loss 0.42033\n",
            "Epoch 350: loss 0.42027\n",
            "Epoch 351: loss 0.42021\n",
            "Epoch 352: loss 0.42016\n",
            "Epoch 353: loss 0.42010\n",
            "Epoch 354: loss 0.42005\n",
            "Epoch 355: loss 0.41999\n",
            "Epoch 356: loss 0.41994\n",
            "Epoch 357: loss 0.41988\n",
            "Epoch 358: loss 0.41983\n",
            "Epoch 359: loss 0.41977\n",
            "Epoch 360: loss 0.41972\n",
            "Epoch 361: loss 0.41967\n",
            "Epoch 362: loss 0.41961\n",
            "Epoch 363: loss 0.41956\n",
            "Epoch 364: loss 0.41951\n",
            "Epoch 365: loss 0.41946\n",
            "Epoch 366: loss 0.41941\n",
            "Epoch 367: loss 0.41936\n",
            "Epoch 368: loss 0.41931\n",
            "Epoch 369: loss 0.41926\n",
            "Epoch 370: loss 0.41921\n",
            "Epoch 371: loss 0.41916\n",
            "Epoch 372: loss 0.41911\n",
            "Epoch 373: loss 0.41906\n",
            "Epoch 374: loss 0.41901\n",
            "Epoch 375: loss 0.41896\n",
            "Epoch 376: loss 0.41891\n",
            "Epoch 377: loss 0.41887\n",
            "Epoch 378: loss 0.41882\n",
            "Epoch 379: loss 0.41877\n",
            "Epoch 380: loss 0.41873\n",
            "Epoch 381: loss 0.41868\n",
            "Epoch 382: loss 0.41863\n",
            "Epoch 383: loss 0.41859\n",
            "Epoch 384: loss 0.41854\n",
            "Epoch 385: loss 0.41850\n",
            "Epoch 386: loss 0.41845\n",
            "Epoch 387: loss 0.41841\n",
            "Epoch 388: loss 0.41836\n",
            "Epoch 389: loss 0.41832\n",
            "Epoch 390: loss 0.41827\n",
            "Epoch 391: loss 0.41823\n",
            "Epoch 392: loss 0.41819\n",
            "Epoch 393: loss 0.41814\n",
            "Epoch 394: loss 0.41810\n",
            "Epoch 395: loss 0.41806\n",
            "Epoch 396: loss 0.41801\n",
            "Epoch 397: loss 0.41797\n",
            "Epoch 398: loss 0.41793\n",
            "Epoch 399: loss 0.41789\n",
            "Epoch 400: loss 0.41785\n",
            "Epoch 401: loss 0.41780\n",
            "Epoch 402: loss 0.41776\n",
            "Epoch 403: loss 0.41772\n",
            "Epoch 404: loss 0.41768\n",
            "Epoch 405: loss 0.41764\n",
            "Epoch 406: loss 0.41760\n",
            "Epoch 407: loss 0.41756\n",
            "Epoch 408: loss 0.41752\n",
            "Epoch 409: loss 0.41748\n",
            "Epoch 410: loss 0.41744\n",
            "Epoch 411: loss 0.41740\n",
            "Epoch 412: loss 0.41736\n",
            "Epoch 413: loss 0.41732\n",
            "Epoch 414: loss 0.41728\n",
            "Epoch 415: loss 0.41725\n",
            "Epoch 416: loss 0.41721\n",
            "Epoch 417: loss 0.41717\n",
            "Epoch 418: loss 0.41713\n",
            "Epoch 419: loss 0.41709\n",
            "Epoch 420: loss 0.41705\n",
            "Epoch 421: loss 0.41702\n",
            "Epoch 422: loss 0.41698\n",
            "Epoch 423: loss 0.41694\n",
            "Epoch 424: loss 0.41690\n",
            "Epoch 425: loss 0.41687\n",
            "Epoch 426: loss 0.41683\n",
            "Epoch 427: loss 0.41679\n",
            "Epoch 428: loss 0.41676\n",
            "Epoch 429: loss 0.41672\n",
            "Epoch 430: loss 0.41668\n",
            "Epoch 431: loss 0.41665\n",
            "Epoch 432: loss 0.41661\n",
            "Epoch 433: loss 0.41657\n",
            "Epoch 434: loss 0.41654\n",
            "Epoch 435: loss 0.41650\n",
            "Epoch 436: loss 0.41647\n",
            "Epoch 437: loss 0.41643\n",
            "Epoch 438: loss 0.41640\n",
            "Epoch 439: loss 0.41636\n",
            "Epoch 440: loss 0.41633\n",
            "Epoch 441: loss 0.41629\n",
            "Epoch 442: loss 0.41626\n",
            "Epoch 443: loss 0.41622\n",
            "Epoch 444: loss 0.41619\n",
            "Epoch 445: loss 0.41615\n",
            "Epoch 446: loss 0.41612\n",
            "Epoch 447: loss 0.41608\n",
            "Epoch 448: loss 0.41605\n",
            "Epoch 449: loss 0.41602\n",
            "Epoch 450: loss 0.41598\n",
            "Epoch 451: loss 0.41595\n",
            "Epoch 452: loss 0.41592\n",
            "Epoch 453: loss 0.41588\n",
            "Epoch 454: loss 0.41585\n",
            "Epoch 455: loss 0.41582\n",
            "Epoch 456: loss 0.41578\n",
            "Epoch 457: loss 0.41575\n",
            "Epoch 458: loss 0.41572\n",
            "Epoch 459: loss 0.41568\n",
            "Epoch 460: loss 0.41565\n",
            "Epoch 461: loss 0.41562\n",
            "Epoch 462: loss 0.41558\n",
            "Epoch 463: loss 0.41555\n",
            "Epoch 464: loss 0.41552\n",
            "Epoch 465: loss 0.41549\n",
            "Epoch 466: loss 0.41545\n",
            "Epoch 467: loss 0.41542\n",
            "Epoch 468: loss 0.41539\n",
            "Epoch 469: loss 0.41536\n",
            "Epoch 470: loss 0.41533\n",
            "Epoch 471: loss 0.41529\n",
            "Epoch 472: loss 0.41526\n",
            "Epoch 473: loss 0.41523\n",
            "Epoch 474: loss 0.41520\n",
            "Epoch 475: loss 0.41517\n",
            "Epoch 476: loss 0.41514\n",
            "Epoch 477: loss 0.41510\n",
            "Epoch 478: loss 0.41507\n",
            "Epoch 479: loss 0.41504\n",
            "Epoch 480: loss 0.41501\n",
            "Epoch 481: loss 0.41498\n",
            "Epoch 482: loss 0.41495\n",
            "Epoch 483: loss 0.41492\n",
            "Epoch 484: loss 0.41489\n",
            "Epoch 485: loss 0.41486\n",
            "Epoch 486: loss 0.41482\n",
            "Epoch 487: loss 0.41479\n",
            "Epoch 488: loss 0.41476\n",
            "Epoch 489: loss 0.41473\n",
            "Epoch 490: loss 0.41470\n",
            "Epoch 491: loss 0.41467\n",
            "Epoch 492: loss 0.41464\n",
            "Epoch 493: loss 0.41461\n",
            "Epoch 494: loss 0.41458\n",
            "Epoch 495: loss 0.41455\n",
            "Epoch 496: loss 0.41452\n",
            "Epoch 497: loss 0.41449\n",
            "Epoch 498: loss 0.41445\n",
            "Epoch 499: loss 0.41442\n",
            "Epoch 500: loss 0.41439\n",
            "Epoch 501: loss 0.41436\n",
            "Epoch 502: loss 0.41433\n",
            "Epoch 503: loss 0.41430\n",
            "Epoch 504: loss 0.41427\n",
            "Epoch 505: loss 0.41424\n",
            "Epoch 506: loss 0.41421\n",
            "Epoch 507: loss 0.41418\n",
            "Epoch 508: loss 0.41415\n",
            "Epoch 509: loss 0.41412\n",
            "Epoch 510: loss 0.41409\n",
            "Epoch 511: loss 0.41406\n",
            "Epoch 512: loss 0.41402\n",
            "Epoch 513: loss 0.41399\n",
            "Epoch 514: loss 0.41396\n",
            "Epoch 515: loss 0.41393\n",
            "Epoch 516: loss 0.41390\n",
            "Epoch 517: loss 0.41387\n",
            "Epoch 518: loss 0.41384\n",
            "Epoch 519: loss 0.41380\n",
            "Epoch 520: loss 0.41377\n",
            "Epoch 521: loss 0.41374\n",
            "Epoch 522: loss 0.41371\n",
            "Epoch 523: loss 0.41368\n",
            "Epoch 524: loss 0.41364\n",
            "Epoch 525: loss 0.41361\n",
            "Epoch 526: loss 0.41358\n",
            "Epoch 527: loss 0.41355\n",
            "Epoch 528: loss 0.41351\n",
            "Epoch 529: loss 0.41348\n",
            "Epoch 530: loss 0.41345\n",
            "Epoch 531: loss 0.41341\n",
            "Epoch 532: loss 0.41338\n",
            "Epoch 533: loss 0.41334\n",
            "Epoch 534: loss 0.41331\n",
            "Epoch 535: loss 0.41328\n",
            "Epoch 536: loss 0.41324\n",
            "Epoch 537: loss 0.41320\n",
            "Epoch 538: loss 0.41317\n",
            "Epoch 539: loss 0.41313\n",
            "Epoch 540: loss 0.41310\n",
            "Epoch 541: loss 0.41306\n",
            "Epoch 542: loss 0.41302\n",
            "Epoch 543: loss 0.41298\n",
            "Epoch 544: loss 0.41295\n",
            "Epoch 545: loss 0.41291\n",
            "Epoch 546: loss 0.41287\n",
            "Epoch 547: loss 0.41283\n",
            "Epoch 548: loss 0.41279\n",
            "Epoch 549: loss 0.41275\n",
            "Epoch 550: loss 0.41271\n",
            "Epoch 551: loss 0.41266\n",
            "Epoch 552: loss 0.41262\n",
            "Epoch 553: loss 0.41258\n",
            "Epoch 554: loss 0.41253\n",
            "Epoch 555: loss 0.41249\n",
            "Epoch 556: loss 0.41245\n",
            "Epoch 557: loss 0.41240\n",
            "Epoch 558: loss 0.41235\n",
            "Epoch 559: loss 0.41231\n",
            "Epoch 560: loss 0.41226\n",
            "Epoch 561: loss 0.41221\n",
            "Epoch 562: loss 0.41216\n",
            "Epoch 563: loss 0.41211\n",
            "Epoch 564: loss 0.41206\n",
            "Epoch 565: loss 0.41201\n",
            "Epoch 566: loss 0.41196\n",
            "Epoch 567: loss 0.41191\n",
            "Epoch 568: loss 0.41186\n",
            "Epoch 569: loss 0.41180\n",
            "Epoch 570: loss 0.41175\n",
            "Epoch 571: loss 0.41170\n",
            "Epoch 572: loss 0.41164\n",
            "Epoch 573: loss 0.41159\n",
            "Epoch 574: loss 0.41153\n",
            "Epoch 575: loss 0.41148\n",
            "Epoch 576: loss 0.41142\n",
            "Epoch 577: loss 0.41137\n",
            "Epoch 578: loss 0.41131\n",
            "Epoch 579: loss 0.41126\n",
            "Epoch 580: loss 0.41120\n",
            "Epoch 581: loss 0.41115\n",
            "Epoch 582: loss 0.41109\n",
            "Epoch 583: loss 0.41104\n",
            "Epoch 584: loss 0.41098\n",
            "Epoch 585: loss 0.41093\n",
            "Epoch 586: loss 0.41088\n",
            "Epoch 587: loss 0.41082\n",
            "Epoch 588: loss 0.41077\n",
            "Epoch 589: loss 0.41071\n",
            "Epoch 590: loss 0.41066\n",
            "Epoch 591: loss 0.41061\n",
            "Epoch 592: loss 0.41056\n",
            "Epoch 593: loss 0.41051\n",
            "Epoch 594: loss 0.41046\n",
            "Epoch 595: loss 0.41041\n",
            "Epoch 596: loss 0.41036\n",
            "Epoch 597: loss 0.41031\n",
            "Epoch 598: loss 0.41026\n",
            "Epoch 599: loss 0.41021\n",
            "Epoch 600: loss 0.41016\n",
            "Epoch 601: loss 0.41011\n",
            "Epoch 602: loss 0.41007\n",
            "Epoch 603: loss 0.41002\n",
            "Epoch 604: loss 0.40997\n",
            "Epoch 605: loss 0.40993\n",
            "Epoch 606: loss 0.40988\n",
            "Epoch 607: loss 0.40984\n",
            "Epoch 608: loss 0.40979\n",
            "Epoch 609: loss 0.40975\n",
            "Epoch 610: loss 0.40970\n",
            "Epoch 611: loss 0.40966\n",
            "Epoch 612: loss 0.40962\n",
            "Epoch 613: loss 0.40957\n",
            "Epoch 614: loss 0.40953\n",
            "Epoch 615: loss 0.40949\n",
            "Epoch 616: loss 0.40945\n",
            "Epoch 617: loss 0.40941\n",
            "Epoch 618: loss 0.40936\n",
            "Epoch 619: loss 0.40932\n",
            "Epoch 620: loss 0.40928\n",
            "Epoch 621: loss 0.40924\n",
            "Epoch 622: loss 0.40920\n",
            "Epoch 623: loss 0.40916\n",
            "Epoch 624: loss 0.40912\n",
            "Epoch 625: loss 0.40908\n",
            "Epoch 626: loss 0.40905\n",
            "Epoch 627: loss 0.40901\n",
            "Epoch 628: loss 0.40897\n",
            "Epoch 629: loss 0.40893\n",
            "Epoch 630: loss 0.40889\n",
            "Epoch 631: loss 0.40885\n",
            "Epoch 632: loss 0.40882\n",
            "Epoch 633: loss 0.40878\n",
            "Epoch 634: loss 0.40874\n",
            "Epoch 635: loss 0.40870\n",
            "Epoch 636: loss 0.40867\n",
            "Epoch 637: loss 0.40863\n",
            "Epoch 638: loss 0.40859\n",
            "Epoch 639: loss 0.40856\n",
            "Epoch 640: loss 0.40852\n",
            "Epoch 641: loss 0.40848\n",
            "Epoch 642: loss 0.40845\n",
            "Epoch 643: loss 0.40841\n",
            "Epoch 644: loss 0.40837\n",
            "Epoch 645: loss 0.40834\n",
            "Epoch 646: loss 0.40830\n",
            "Epoch 647: loss 0.40827\n",
            "Epoch 648: loss 0.40823\n",
            "Epoch 649: loss 0.40820\n",
            "Epoch 650: loss 0.40816\n",
            "Epoch 651: loss 0.40813\n",
            "Epoch 652: loss 0.40809\n",
            "Epoch 653: loss 0.40806\n",
            "Epoch 654: loss 0.40802\n",
            "Epoch 655: loss 0.40799\n",
            "Epoch 656: loss 0.40795\n",
            "Epoch 657: loss 0.40792\n",
            "Epoch 658: loss 0.40789\n",
            "Epoch 659: loss 0.40785\n",
            "Epoch 660: loss 0.40782\n",
            "Epoch 661: loss 0.40778\n",
            "Epoch 662: loss 0.40775\n",
            "Epoch 663: loss 0.40772\n",
            "Epoch 664: loss 0.40768\n",
            "Epoch 665: loss 0.40765\n",
            "Epoch 666: loss 0.40761\n",
            "Epoch 667: loss 0.40758\n",
            "Epoch 668: loss 0.40755\n",
            "Epoch 669: loss 0.40751\n",
            "Epoch 670: loss 0.40748\n",
            "Epoch 671: loss 0.40745\n",
            "Epoch 672: loss 0.40742\n",
            "Epoch 673: loss 0.40738\n",
            "Epoch 674: loss 0.40735\n",
            "Epoch 675: loss 0.40732\n",
            "Epoch 676: loss 0.40728\n",
            "Epoch 677: loss 0.40725\n",
            "Epoch 678: loss 0.40722\n",
            "Epoch 679: loss 0.40719\n",
            "Epoch 680: loss 0.40715\n",
            "Epoch 681: loss 0.40712\n",
            "Epoch 682: loss 0.40709\n",
            "Epoch 683: loss 0.40706\n",
            "Epoch 684: loss 0.40703\n",
            "Epoch 685: loss 0.40699\n",
            "Epoch 686: loss 0.40696\n",
            "Epoch 687: loss 0.40693\n",
            "Epoch 688: loss 0.40690\n",
            "Epoch 689: loss 0.40687\n",
            "Epoch 690: loss 0.40683\n",
            "Epoch 691: loss 0.40680\n",
            "Epoch 692: loss 0.40677\n",
            "Epoch 693: loss 0.40674\n",
            "Epoch 694: loss 0.40671\n",
            "Epoch 695: loss 0.40668\n",
            "Epoch 696: loss 0.40664\n",
            "Epoch 697: loss 0.40661\n",
            "Epoch 698: loss 0.40658\n",
            "Epoch 699: loss 0.40655\n",
            "Epoch 700: loss 0.40652\n",
            "Epoch 701: loss 0.40649\n",
            "Epoch 702: loss 0.40646\n",
            "Epoch 703: loss 0.40642\n",
            "Epoch 704: loss 0.40639\n",
            "Epoch 705: loss 0.40636\n",
            "Epoch 706: loss 0.40633\n",
            "Epoch 707: loss 0.40630\n",
            "Epoch 708: loss 0.40627\n",
            "Epoch 709: loss 0.40624\n",
            "Epoch 710: loss 0.40621\n",
            "Epoch 711: loss 0.40618\n",
            "Epoch 712: loss 0.40615\n",
            "Epoch 713: loss 0.40612\n",
            "Epoch 714: loss 0.40609\n",
            "Epoch 715: loss 0.40605\n",
            "Epoch 716: loss 0.40602\n",
            "Epoch 717: loss 0.40599\n",
            "Epoch 718: loss 0.40596\n",
            "Epoch 719: loss 0.40593\n",
            "Epoch 720: loss 0.40590\n",
            "Epoch 721: loss 0.40587\n",
            "Epoch 722: loss 0.40584\n",
            "Epoch 723: loss 0.40581\n",
            "Epoch 724: loss 0.40578\n",
            "Epoch 725: loss 0.40575\n",
            "Epoch 726: loss 0.40572\n",
            "Epoch 727: loss 0.40569\n",
            "Epoch 728: loss 0.40566\n",
            "Epoch 729: loss 0.40563\n",
            "Epoch 730: loss 0.40560\n",
            "Epoch 731: loss 0.40557\n",
            "Epoch 732: loss 0.40554\n",
            "Epoch 733: loss 0.40551\n",
            "Epoch 734: loss 0.40548\n",
            "Epoch 735: loss 0.40545\n",
            "Epoch 736: loss 0.40542\n",
            "Epoch 737: loss 0.40539\n",
            "Epoch 738: loss 0.40535\n",
            "Epoch 739: loss 0.40532\n",
            "Epoch 740: loss 0.40529\n",
            "Epoch 741: loss 0.40526\n",
            "Epoch 742: loss 0.40523\n",
            "Epoch 743: loss 0.40520\n",
            "Epoch 744: loss 0.40517\n",
            "Epoch 745: loss 0.40514\n",
            "Epoch 746: loss 0.40511\n",
            "Epoch 747: loss 0.40508\n",
            "Epoch 748: loss 0.40505\n",
            "Epoch 749: loss 0.40502\n",
            "Epoch 750: loss 0.40499\n",
            "Epoch 751: loss 0.40496\n",
            "Epoch 752: loss 0.40493\n",
            "Epoch 753: loss 0.40490\n",
            "Epoch 754: loss 0.40487\n",
            "Epoch 755: loss 0.40484\n",
            "Epoch 756: loss 0.40481\n",
            "Epoch 757: loss 0.40478\n",
            "Epoch 758: loss 0.40475\n",
            "Epoch 759: loss 0.40472\n",
            "Epoch 760: loss 0.40468\n",
            "Epoch 761: loss 0.40465\n",
            "Epoch 762: loss 0.40462\n",
            "Epoch 763: loss 0.40459\n",
            "Epoch 764: loss 0.40456\n",
            "Epoch 765: loss 0.40453\n",
            "Epoch 766: loss 0.40450\n",
            "Epoch 767: loss 0.40447\n",
            "Epoch 768: loss 0.40444\n",
            "Epoch 769: loss 0.40440\n",
            "Epoch 770: loss 0.40437\n",
            "Epoch 771: loss 0.40434\n",
            "Epoch 772: loss 0.40431\n",
            "Epoch 773: loss 0.40428\n",
            "Epoch 774: loss 0.40425\n",
            "Epoch 775: loss 0.40422\n",
            "Epoch 776: loss 0.40418\n",
            "Epoch 777: loss 0.40415\n",
            "Epoch 778: loss 0.40412\n",
            "Epoch 779: loss 0.40409\n",
            "Epoch 780: loss 0.40406\n",
            "Epoch 781: loss 0.40402\n",
            "Epoch 782: loss 0.40399\n",
            "Epoch 783: loss 0.40396\n",
            "Epoch 784: loss 0.40393\n",
            "Epoch 785: loss 0.40389\n",
            "Epoch 786: loss 0.40386\n",
            "Epoch 787: loss 0.40383\n",
            "Epoch 788: loss 0.40379\n",
            "Epoch 789: loss 0.40376\n",
            "Epoch 790: loss 0.40373\n",
            "Epoch 791: loss 0.40369\n",
            "Epoch 792: loss 0.40366\n",
            "Epoch 793: loss 0.40363\n",
            "Epoch 794: loss 0.40359\n",
            "Epoch 795: loss 0.40356\n",
            "Epoch 796: loss 0.40352\n",
            "Epoch 797: loss 0.40349\n",
            "Epoch 798: loss 0.40345\n",
            "Epoch 799: loss 0.40342\n",
            "Epoch 800: loss 0.40338\n",
            "Epoch 801: loss 0.40335\n",
            "Epoch 802: loss 0.40331\n",
            "Epoch 803: loss 0.40328\n",
            "Epoch 804: loss 0.40324\n",
            "Epoch 805: loss 0.40321\n",
            "Epoch 806: loss 0.40317\n",
            "Epoch 807: loss 0.40313\n",
            "Epoch 808: loss 0.40310\n",
            "Epoch 809: loss 0.40306\n",
            "Epoch 810: loss 0.40302\n",
            "Epoch 811: loss 0.40299\n",
            "Epoch 812: loss 0.40295\n",
            "Epoch 813: loss 0.40291\n",
            "Epoch 814: loss 0.40287\n",
            "Epoch 815: loss 0.40283\n",
            "Epoch 816: loss 0.40280\n",
            "Epoch 817: loss 0.40276\n",
            "Epoch 818: loss 0.40272\n",
            "Epoch 819: loss 0.40268\n",
            "Epoch 820: loss 0.40264\n",
            "Epoch 821: loss 0.40260\n",
            "Epoch 822: loss 0.40256\n",
            "Epoch 823: loss 0.40252\n",
            "Epoch 824: loss 0.40248\n",
            "Epoch 825: loss 0.40244\n",
            "Epoch 826: loss 0.40239\n",
            "Epoch 827: loss 0.40235\n",
            "Epoch 828: loss 0.40231\n",
            "Epoch 829: loss 0.40227\n",
            "Epoch 830: loss 0.40223\n",
            "Epoch 831: loss 0.40218\n",
            "Epoch 832: loss 0.40214\n",
            "Epoch 833: loss 0.40210\n",
            "Epoch 834: loss 0.40205\n",
            "Epoch 835: loss 0.40201\n",
            "Epoch 836: loss 0.40196\n",
            "Epoch 837: loss 0.40192\n",
            "Epoch 838: loss 0.40187\n",
            "Epoch 839: loss 0.40183\n",
            "Epoch 840: loss 0.40178\n",
            "Epoch 841: loss 0.40173\n",
            "Epoch 842: loss 0.40169\n",
            "Epoch 843: loss 0.40164\n",
            "Epoch 844: loss 0.40159\n",
            "Epoch 845: loss 0.40154\n",
            "Epoch 846: loss 0.40150\n",
            "Epoch 847: loss 0.40145\n",
            "Epoch 848: loss 0.40140\n",
            "Epoch 849: loss 0.40135\n",
            "Epoch 850: loss 0.40130\n",
            "Epoch 851: loss 0.40125\n",
            "Epoch 852: loss 0.40120\n",
            "Epoch 853: loss 0.40115\n",
            "Epoch 854: loss 0.40109\n",
            "Epoch 855: loss 0.40104\n",
            "Epoch 856: loss 0.40099\n",
            "Epoch 857: loss 0.40094\n",
            "Epoch 858: loss 0.40088\n",
            "Epoch 859: loss 0.40083\n",
            "Epoch 860: loss 0.40078\n",
            "Epoch 861: loss 0.40072\n",
            "Epoch 862: loss 0.40067\n",
            "Epoch 863: loss 0.40061\n",
            "Epoch 864: loss 0.40056\n",
            "Epoch 865: loss 0.40050\n",
            "Epoch 866: loss 0.40045\n",
            "Epoch 867: loss 0.40039\n",
            "Epoch 868: loss 0.40033\n",
            "Epoch 869: loss 0.40027\n",
            "Epoch 870: loss 0.40022\n",
            "Epoch 871: loss 0.40016\n",
            "Epoch 872: loss 0.40010\n",
            "Epoch 873: loss 0.40004\n",
            "Epoch 874: loss 0.39998\n",
            "Epoch 875: loss 0.39992\n",
            "Epoch 876: loss 0.39986\n",
            "Epoch 877: loss 0.39980\n",
            "Epoch 878: loss 0.39974\n",
            "Epoch 879: loss 0.39968\n",
            "Epoch 880: loss 0.39962\n",
            "Epoch 881: loss 0.39955\n",
            "Epoch 882: loss 0.39949\n",
            "Epoch 883: loss 0.39943\n",
            "Epoch 884: loss 0.39936\n",
            "Epoch 885: loss 0.39930\n",
            "Epoch 886: loss 0.39924\n",
            "Epoch 887: loss 0.39917\n",
            "Epoch 888: loss 0.39911\n",
            "Epoch 889: loss 0.39904\n",
            "Epoch 890: loss 0.39898\n",
            "Epoch 891: loss 0.39891\n",
            "Epoch 892: loss 0.39885\n",
            "Epoch 893: loss 0.39878\n",
            "Epoch 894: loss 0.39871\n",
            "Epoch 895: loss 0.39865\n",
            "Epoch 896: loss 0.39858\n",
            "Epoch 897: loss 0.39851\n",
            "Epoch 898: loss 0.39845\n",
            "Epoch 899: loss 0.39838\n",
            "Epoch 900: loss 0.39831\n",
            "Epoch 901: loss 0.39824\n",
            "Epoch 902: loss 0.39818\n",
            "Epoch 903: loss 0.39811\n",
            "Epoch 904: loss 0.39804\n",
            "Epoch 905: loss 0.39797\n",
            "Epoch 906: loss 0.39790\n",
            "Epoch 907: loss 0.39783\n",
            "Epoch 908: loss 0.39776\n",
            "Epoch 909: loss 0.39770\n",
            "Epoch 910: loss 0.39763\n",
            "Epoch 911: loss 0.39756\n",
            "Epoch 912: loss 0.39749\n",
            "Epoch 913: loss 0.39742\n",
            "Epoch 914: loss 0.39735\n",
            "Epoch 915: loss 0.39728\n",
            "Epoch 916: loss 0.39721\n",
            "Epoch 917: loss 0.39714\n",
            "Epoch 918: loss 0.39707\n",
            "Epoch 919: loss 0.39700\n",
            "Epoch 920: loss 0.39693\n",
            "Epoch 921: loss 0.39686\n",
            "Epoch 922: loss 0.39679\n",
            "Epoch 923: loss 0.39672\n",
            "Epoch 924: loss 0.39664\n",
            "Epoch 925: loss 0.39657\n",
            "Epoch 926: loss 0.39650\n",
            "Epoch 927: loss 0.39643\n",
            "Epoch 928: loss 0.39636\n",
            "Epoch 929: loss 0.39629\n",
            "Epoch 930: loss 0.39622\n",
            "Epoch 931: loss 0.39615\n",
            "Epoch 932: loss 0.39608\n",
            "Epoch 933: loss 0.39601\n",
            "Epoch 934: loss 0.39594\n",
            "Epoch 935: loss 0.39587\n",
            "Epoch 936: loss 0.39579\n",
            "Epoch 937: loss 0.39572\n",
            "Epoch 938: loss 0.39565\n",
            "Epoch 939: loss 0.39558\n",
            "Epoch 940: loss 0.39551\n",
            "Epoch 941: loss 0.39544\n",
            "Epoch 942: loss 0.39537\n",
            "Epoch 943: loss 0.39530\n",
            "Epoch 944: loss 0.39523\n",
            "Epoch 945: loss 0.39516\n",
            "Epoch 946: loss 0.39509\n",
            "Epoch 947: loss 0.39502\n",
            "Epoch 948: loss 0.39495\n",
            "Epoch 949: loss 0.39488\n",
            "Epoch 950: loss 0.39481\n",
            "Epoch 951: loss 0.39474\n",
            "Epoch 952: loss 0.39467\n",
            "Epoch 953: loss 0.39460\n",
            "Epoch 954: loss 0.39453\n",
            "Epoch 955: loss 0.39446\n",
            "Epoch 956: loss 0.39439\n",
            "Epoch 957: loss 0.39432\n",
            "Epoch 958: loss 0.39425\n",
            "Epoch 959: loss 0.39418\n",
            "Epoch 960: loss 0.39411\n",
            "Epoch 961: loss 0.39404\n",
            "Epoch 962: loss 0.39397\n",
            "Epoch 963: loss 0.39390\n",
            "Epoch 964: loss 0.39384\n",
            "Epoch 965: loss 0.39377\n",
            "Epoch 966: loss 0.39370\n",
            "Epoch 967: loss 0.39363\n",
            "Epoch 968: loss 0.39357\n",
            "Epoch 969: loss 0.39350\n",
            "Epoch 970: loss 0.39343\n",
            "Epoch 971: loss 0.39337\n",
            "Epoch 972: loss 0.39330\n",
            "Epoch 973: loss 0.39323\n",
            "Epoch 974: loss 0.39317\n",
            "Epoch 975: loss 0.39310\n",
            "Epoch 976: loss 0.39303\n",
            "Epoch 977: loss 0.39297\n",
            "Epoch 978: loss 0.39290\n",
            "Epoch 979: loss 0.39284\n",
            "Epoch 980: loss 0.39277\n",
            "Epoch 981: loss 0.39271\n",
            "Epoch 982: loss 0.39264\n",
            "Epoch 983: loss 0.39258\n",
            "Epoch 984: loss 0.39252\n",
            "Epoch 985: loss 0.39245\n",
            "Epoch 986: loss 0.39239\n",
            "Epoch 987: loss 0.39232\n",
            "Epoch 988: loss 0.39226\n",
            "Epoch 989: loss 0.39220\n",
            "Epoch 990: loss 0.39214\n",
            "Epoch 991: loss 0.39207\n",
            "Epoch 992: loss 0.39201\n",
            "Epoch 993: loss 0.39195\n",
            "Epoch 994: loss 0.39188\n",
            "Epoch 995: loss 0.39182\n",
            "Epoch 996: loss 0.39176\n",
            "Epoch 997: loss 0.39170\n",
            "Epoch 998: loss 0.39164\n",
            "Epoch 999: loss 0.39157\n",
            "Epoch 1000: loss 0.39151\n",
            "Epoch 1001: loss 0.39145\n",
            "Epoch 1002: loss 0.39139\n",
            "Epoch 1003: loss 0.39133\n",
            "Epoch 1004: loss 0.39127\n",
            "Epoch 1005: loss 0.39121\n",
            "Epoch 1006: loss 0.39115\n",
            "Epoch 1007: loss 0.39109\n",
            "Epoch 1008: loss 0.39103\n",
            "Epoch 1009: loss 0.39097\n",
            "Epoch 1010: loss 0.39091\n",
            "Epoch 1011: loss 0.39085\n",
            "Epoch 1012: loss 0.39079\n",
            "Epoch 1013: loss 0.39073\n",
            "Epoch 1014: loss 0.39067\n",
            "Epoch 1015: loss 0.39061\n",
            "Epoch 1016: loss 0.39055\n",
            "Epoch 1017: loss 0.39049\n",
            "Epoch 1018: loss 0.39043\n",
            "Epoch 1019: loss 0.39037\n",
            "Epoch 1020: loss 0.39032\n",
            "Epoch 1021: loss 0.39026\n",
            "Epoch 1022: loss 0.39020\n",
            "Epoch 1023: loss 0.39014\n",
            "Epoch 1024: loss 0.39008\n",
            "Epoch 1025: loss 0.39002\n",
            "Epoch 1026: loss 0.38997\n",
            "Epoch 1027: loss 0.38991\n",
            "Epoch 1028: loss 0.38985\n",
            "Epoch 1029: loss 0.38979\n",
            "Epoch 1030: loss 0.38974\n",
            "Epoch 1031: loss 0.38968\n",
            "Epoch 1032: loss 0.38962\n",
            "Epoch 1033: loss 0.38957\n",
            "Epoch 1034: loss 0.38951\n",
            "Epoch 1035: loss 0.38945\n",
            "Epoch 1036: loss 0.38940\n",
            "Epoch 1037: loss 0.38934\n",
            "Epoch 1038: loss 0.38929\n",
            "Epoch 1039: loss 0.38923\n",
            "Epoch 1040: loss 0.38918\n",
            "Epoch 1041: loss 0.38912\n",
            "Epoch 1042: loss 0.38907\n",
            "Epoch 1043: loss 0.38901\n",
            "Epoch 1044: loss 0.38896\n",
            "Epoch 1045: loss 0.38890\n",
            "Epoch 1046: loss 0.38885\n",
            "Epoch 1047: loss 0.38879\n",
            "Epoch 1048: loss 0.38874\n",
            "Epoch 1049: loss 0.38868\n",
            "Epoch 1050: loss 0.38863\n",
            "Epoch 1051: loss 0.38858\n",
            "Epoch 1052: loss 0.38852\n",
            "Epoch 1053: loss 0.38847\n",
            "Epoch 1054: loss 0.38842\n",
            "Epoch 1055: loss 0.38836\n",
            "Epoch 1056: loss 0.38831\n",
            "Epoch 1057: loss 0.38826\n",
            "Epoch 1058: loss 0.38821\n",
            "Epoch 1059: loss 0.38815\n",
            "Epoch 1060: loss 0.38810\n",
            "Epoch 1061: loss 0.38805\n",
            "Epoch 1062: loss 0.38800\n",
            "Epoch 1063: loss 0.38795\n",
            "Epoch 1064: loss 0.38790\n",
            "Epoch 1065: loss 0.38785\n",
            "Epoch 1066: loss 0.38780\n",
            "Epoch 1067: loss 0.38774\n",
            "Epoch 1068: loss 0.38769\n",
            "Epoch 1069: loss 0.38764\n",
            "Epoch 1070: loss 0.38759\n",
            "Epoch 1071: loss 0.38755\n",
            "Epoch 1072: loss 0.38750\n",
            "Epoch 1073: loss 0.38745\n",
            "Epoch 1074: loss 0.38740\n",
            "Epoch 1075: loss 0.38735\n",
            "Epoch 1076: loss 0.38730\n",
            "Epoch 1077: loss 0.38725\n",
            "Epoch 1078: loss 0.38720\n",
            "Epoch 1079: loss 0.38716\n",
            "Epoch 1080: loss 0.38711\n",
            "Epoch 1081: loss 0.38706\n",
            "Epoch 1082: loss 0.38702\n",
            "Epoch 1083: loss 0.38697\n",
            "Epoch 1084: loss 0.38692\n",
            "Epoch 1085: loss 0.38688\n",
            "Epoch 1086: loss 0.38683\n",
            "Epoch 1087: loss 0.38678\n",
            "Epoch 1088: loss 0.38674\n",
            "Epoch 1089: loss 0.38669\n",
            "Epoch 1090: loss 0.38665\n",
            "Epoch 1091: loss 0.38661\n",
            "Epoch 1092: loss 0.38656\n",
            "Epoch 1093: loss 0.38652\n",
            "Epoch 1094: loss 0.38647\n",
            "Epoch 1095: loss 0.38643\n",
            "Epoch 1096: loss 0.38639\n",
            "Epoch 1097: loss 0.38635\n",
            "Epoch 1098: loss 0.38630\n",
            "Epoch 1099: loss 0.38626\n",
            "Epoch 1100: loss 0.38622\n",
            "Epoch 1101: loss 0.38618\n",
            "Epoch 1102: loss 0.38614\n",
            "Epoch 1103: loss 0.38610\n",
            "Epoch 1104: loss 0.38606\n",
            "Epoch 1105: loss 0.38602\n",
            "Epoch 1106: loss 0.38598\n",
            "Epoch 1107: loss 0.38594\n",
            "Epoch 1108: loss 0.38590\n",
            "Epoch 1109: loss 0.38586\n",
            "Epoch 1110: loss 0.38583\n",
            "Epoch 1111: loss 0.38579\n",
            "Epoch 1112: loss 0.38575\n",
            "Epoch 1113: loss 0.38572\n",
            "Epoch 1114: loss 0.38568\n",
            "Epoch 1115: loss 0.38565\n",
            "Epoch 1116: loss 0.38561\n",
            "Epoch 1117: loss 0.38558\n",
            "Epoch 1118: loss 0.38554\n",
            "Epoch 1119: loss 0.38551\n",
            "Epoch 1120: loss 0.38548\n",
            "Epoch 1121: loss 0.38544\n",
            "Epoch 1122: loss 0.38541\n",
            "Epoch 1123: loss 0.38538\n",
            "Epoch 1124: loss 0.38535\n",
            "Epoch 1125: loss 0.38532\n",
            "Epoch 1126: loss 0.38529\n",
            "Epoch 1127: loss 0.38526\n",
            "Epoch 1128: loss 0.38523\n",
            "Epoch 1129: loss 0.38520\n",
            "Epoch 1130: loss 0.38517\n",
            "Epoch 1131: loss 0.38514\n",
            "Epoch 1132: loss 0.38512\n",
            "Epoch 1133: loss 0.38509\n",
            "Epoch 1134: loss 0.38506\n",
            "Epoch 1135: loss 0.38504\n",
            "Epoch 1136: loss 0.38501\n",
            "Epoch 1137: loss 0.38498\n",
            "Epoch 1138: loss 0.38496\n",
            "Epoch 1139: loss 0.38493\n",
            "Epoch 1140: loss 0.38491\n",
            "Epoch 1141: loss 0.38489\n",
            "Epoch 1142: loss 0.38486\n",
            "Epoch 1143: loss 0.38484\n",
            "Epoch 1144: loss 0.38482\n",
            "Epoch 1145: loss 0.38479\n",
            "Epoch 1146: loss 0.38477\n",
            "Epoch 1147: loss 0.38475\n",
            "Epoch 1148: loss 0.38473\n",
            "Epoch 1149: loss 0.38471\n",
            "Epoch 1150: loss 0.38469\n",
            "Epoch 1151: loss 0.38467\n",
            "Epoch 1152: loss 0.38465\n",
            "Epoch 1153: loss 0.38462\n",
            "Epoch 1154: loss 0.38460\n",
            "Epoch 1155: loss 0.38459\n",
            "Epoch 1156: loss 0.38457\n",
            "Epoch 1157: loss 0.38455\n",
            "Epoch 1158: loss 0.38453\n",
            "Epoch 1159: loss 0.38451\n",
            "Epoch 1160: loss 0.38449\n",
            "Epoch 1161: loss 0.38447\n",
            "Epoch 1162: loss 0.38445\n",
            "Epoch 1163: loss 0.38443\n",
            "Epoch 1164: loss 0.38442\n",
            "Epoch 1165: loss 0.38440\n",
            "Epoch 1166: loss 0.38438\n",
            "Epoch 1167: loss 0.38436\n",
            "Epoch 1168: loss 0.38434\n",
            "Epoch 1169: loss 0.38433\n",
            "Epoch 1170: loss 0.38431\n",
            "Epoch 1171: loss 0.38429\n",
            "Epoch 1172: loss 0.38427\n",
            "Epoch 1173: loss 0.38426\n",
            "Epoch 1174: loss 0.38424\n",
            "Epoch 1175: loss 0.38422\n",
            "Epoch 1176: loss 0.38421\n",
            "Epoch 1177: loss 0.38419\n",
            "Epoch 1178: loss 0.38417\n",
            "Epoch 1179: loss 0.38415\n",
            "Epoch 1180: loss 0.38414\n",
            "Epoch 1181: loss 0.38412\n",
            "Epoch 1182: loss 0.38410\n",
            "Epoch 1183: loss 0.38408\n",
            "Epoch 1184: loss 0.38407\n",
            "Epoch 1185: loss 0.38405\n",
            "Epoch 1186: loss 0.38403\n",
            "Epoch 1187: loss 0.38401\n",
            "Epoch 1188: loss 0.38400\n",
            "Epoch 1189: loss 0.38398\n",
            "Epoch 1190: loss 0.38396\n",
            "Epoch 1191: loss 0.38394\n",
            "Epoch 1192: loss 0.38393\n",
            "Epoch 1193: loss 0.38391\n",
            "Epoch 1194: loss 0.38389\n",
            "Epoch 1195: loss 0.38387\n",
            "Epoch 1196: loss 0.38385\n",
            "Epoch 1197: loss 0.38383\n",
            "Epoch 1198: loss 0.38382\n",
            "Epoch 1199: loss 0.38380\n",
            "Epoch 1200: loss 0.38378\n",
            "Epoch 1201: loss 0.38376\n",
            "Epoch 1202: loss 0.38374\n",
            "Epoch 1203: loss 0.38372\n",
            "Epoch 1204: loss 0.38370\n",
            "Epoch 1205: loss 0.38368\n",
            "Epoch 1206: loss 0.38366\n",
            "Epoch 1207: loss 0.38364\n",
            "Epoch 1208: loss 0.38362\n",
            "Epoch 1209: loss 0.38360\n",
            "Epoch 1210: loss 0.38358\n",
            "Epoch 1211: loss 0.38356\n",
            "Epoch 1212: loss 0.38354\n",
            "Epoch 1213: loss 0.38352\n",
            "Epoch 1214: loss 0.38349\n",
            "Epoch 1215: loss 0.38347\n",
            "Epoch 1216: loss 0.38345\n",
            "Epoch 1217: loss 0.38343\n",
            "Epoch 1218: loss 0.38341\n",
            "Epoch 1219: loss 0.38338\n",
            "Epoch 1220: loss 0.38336\n",
            "Epoch 1221: loss 0.38334\n",
            "Epoch 1222: loss 0.38332\n",
            "Epoch 1223: loss 0.38329\n",
            "Epoch 1224: loss 0.38327\n",
            "Epoch 1225: loss 0.38325\n",
            "Epoch 1226: loss 0.38322\n",
            "Epoch 1227: loss 0.38320\n",
            "Epoch 1228: loss 0.38318\n",
            "Epoch 1229: loss 0.38315\n",
            "Epoch 1230: loss 0.38313\n",
            "Epoch 1231: loss 0.38310\n",
            "Epoch 1232: loss 0.38308\n",
            "Epoch 1233: loss 0.38305\n",
            "Epoch 1234: loss 0.38303\n",
            "Epoch 1235: loss 0.38300\n",
            "Epoch 1236: loss 0.38298\n",
            "Epoch 1237: loss 0.38295\n",
            "Epoch 1238: loss 0.38293\n",
            "Epoch 1239: loss 0.38290\n",
            "Epoch 1240: loss 0.38288\n",
            "Epoch 1241: loss 0.38285\n",
            "Epoch 1242: loss 0.38283\n",
            "Epoch 1243: loss 0.38280\n",
            "Epoch 1244: loss 0.38277\n",
            "Epoch 1245: loss 0.38275\n",
            "Epoch 1246: loss 0.38272\n",
            "Epoch 1247: loss 0.38270\n",
            "Epoch 1248: loss 0.38267\n",
            "Epoch 1249: loss 0.38264\n",
            "Epoch 1250: loss 0.38262\n",
            "Epoch 1251: loss 0.38259\n",
            "Epoch 1252: loss 0.38256\n",
            "Epoch 1253: loss 0.38254\n",
            "Epoch 1254: loss 0.38251\n",
            "Epoch 1255: loss 0.38249\n",
            "Epoch 1256: loss 0.38246\n",
            "Epoch 1257: loss 0.38243\n",
            "Epoch 1258: loss 0.38241\n",
            "Epoch 1259: loss 0.38238\n",
            "Epoch 1260: loss 0.38236\n",
            "Epoch 1261: loss 0.38233\n",
            "Epoch 1262: loss 0.38230\n",
            "Epoch 1263: loss 0.38228\n",
            "Epoch 1264: loss 0.38225\n",
            "Epoch 1265: loss 0.38223\n",
            "Epoch 1266: loss 0.38220\n",
            "Epoch 1267: loss 0.38218\n",
            "Epoch 1268: loss 0.38215\n",
            "Epoch 1269: loss 0.38213\n",
            "Epoch 1270: loss 0.38210\n",
            "Epoch 1271: loss 0.38207\n",
            "Epoch 1272: loss 0.38205\n",
            "Epoch 1273: loss 0.38202\n",
            "Epoch 1274: loss 0.38200\n",
            "Epoch 1275: loss 0.38197\n",
            "Epoch 1276: loss 0.38195\n",
            "Epoch 1277: loss 0.38192\n",
            "Epoch 1278: loss 0.38190\n",
            "Epoch 1279: loss 0.38187\n",
            "Epoch 1280: loss 0.38185\n",
            "Epoch 1281: loss 0.38182\n",
            "Epoch 1282: loss 0.38180\n",
            "Epoch 1283: loss 0.38178\n",
            "Epoch 1284: loss 0.38175\n",
            "Epoch 1285: loss 0.38173\n",
            "Epoch 1286: loss 0.38170\n",
            "Epoch 1287: loss 0.38168\n",
            "Epoch 1288: loss 0.38165\n",
            "Epoch 1289: loss 0.38163\n",
            "Epoch 1290: loss 0.38160\n",
            "Epoch 1291: loss 0.38158\n",
            "Epoch 1292: loss 0.38156\n",
            "Epoch 1293: loss 0.38153\n",
            "Epoch 1294: loss 0.38151\n",
            "Epoch 1295: loss 0.38148\n",
            "Epoch 1296: loss 0.38146\n",
            "Epoch 1297: loss 0.38143\n",
            "Epoch 1298: loss 0.38141\n",
            "Epoch 1299: loss 0.38139\n",
            "Epoch 1300: loss 0.38136\n",
            "Epoch 1301: loss 0.38134\n",
            "Epoch 1302: loss 0.38131\n",
            "Epoch 1303: loss 0.38129\n",
            "Epoch 1304: loss 0.38126\n",
            "Epoch 1305: loss 0.38124\n",
            "Epoch 1306: loss 0.38122\n",
            "Epoch 1307: loss 0.38119\n",
            "Epoch 1308: loss 0.38117\n",
            "Epoch 1309: loss 0.38114\n",
            "Epoch 1310: loss 0.38112\n",
            "Epoch 1311: loss 0.38110\n",
            "Epoch 1312: loss 0.38107\n",
            "Epoch 1313: loss 0.38105\n",
            "Epoch 1314: loss 0.38102\n",
            "Epoch 1315: loss 0.38100\n",
            "Epoch 1316: loss 0.38097\n",
            "Epoch 1317: loss 0.38095\n",
            "Epoch 1318: loss 0.38092\n",
            "Epoch 1319: loss 0.38090\n",
            "Epoch 1320: loss 0.38088\n",
            "Epoch 1321: loss 0.38085\n",
            "Epoch 1322: loss 0.38083\n",
            "Epoch 1323: loss 0.38080\n",
            "Epoch 1324: loss 0.38078\n",
            "Epoch 1325: loss 0.38075\n",
            "Epoch 1326: loss 0.38073\n",
            "Epoch 1327: loss 0.38071\n",
            "Epoch 1328: loss 0.38068\n",
            "Epoch 1329: loss 0.38066\n",
            "Epoch 1330: loss 0.38063\n",
            "Epoch 1331: loss 0.38061\n",
            "Epoch 1332: loss 0.38058\n",
            "Epoch 1333: loss 0.38056\n",
            "Epoch 1334: loss 0.38054\n",
            "Epoch 1335: loss 0.38051\n",
            "Epoch 1336: loss 0.38049\n",
            "Epoch 1337: loss 0.38046\n",
            "Epoch 1338: loss 0.38044\n",
            "Epoch 1339: loss 0.38041\n",
            "Epoch 1340: loss 0.38039\n",
            "Epoch 1341: loss 0.38037\n",
            "Epoch 1342: loss 0.38034\n",
            "Epoch 1343: loss 0.38032\n",
            "Epoch 1344: loss 0.38029\n",
            "Epoch 1345: loss 0.38027\n",
            "Epoch 1346: loss 0.38025\n",
            "Epoch 1347: loss 0.38022\n",
            "Epoch 1348: loss 0.38020\n",
            "Epoch 1349: loss 0.38017\n",
            "Epoch 1350: loss 0.38015\n",
            "Epoch 1351: loss 0.38013\n",
            "Epoch 1352: loss 0.38010\n",
            "Epoch 1353: loss 0.38008\n",
            "Epoch 1354: loss 0.38006\n",
            "Epoch 1355: loss 0.38003\n",
            "Epoch 1356: loss 0.38001\n",
            "Epoch 1357: loss 0.37999\n",
            "Epoch 1358: loss 0.37996\n",
            "Epoch 1359: loss 0.37994\n",
            "Epoch 1360: loss 0.37992\n",
            "Epoch 1361: loss 0.37989\n",
            "Epoch 1362: loss 0.37987\n",
            "Epoch 1363: loss 0.37985\n",
            "Epoch 1364: loss 0.37982\n",
            "Epoch 1365: loss 0.37980\n",
            "Epoch 1366: loss 0.37978\n",
            "Epoch 1367: loss 0.37975\n",
            "Epoch 1368: loss 0.37973\n",
            "Epoch 1369: loss 0.37971\n",
            "Epoch 1370: loss 0.37968\n",
            "Epoch 1371: loss 0.37966\n",
            "Epoch 1372: loss 0.37964\n",
            "Epoch 1373: loss 0.37962\n",
            "Epoch 1374: loss 0.37959\n",
            "Epoch 1375: loss 0.37957\n",
            "Epoch 1376: loss 0.37955\n",
            "Epoch 1377: loss 0.37952\n",
            "Epoch 1378: loss 0.37950\n",
            "Epoch 1379: loss 0.37948\n",
            "Epoch 1380: loss 0.37946\n",
            "Epoch 1381: loss 0.37943\n",
            "Epoch 1382: loss 0.37941\n",
            "Epoch 1383: loss 0.37939\n",
            "Epoch 1384: loss 0.37937\n",
            "Epoch 1385: loss 0.37934\n",
            "Epoch 1386: loss 0.37932\n",
            "Epoch 1387: loss 0.37930\n",
            "Epoch 1388: loss 0.37928\n",
            "Epoch 1389: loss 0.37926\n",
            "Epoch 1390: loss 0.37923\n",
            "Epoch 1391: loss 0.37921\n",
            "Epoch 1392: loss 0.37919\n",
            "Epoch 1393: loss 0.37917\n",
            "Epoch 1394: loss 0.37914\n",
            "Epoch 1395: loss 0.37912\n",
            "Epoch 1396: loss 0.37910\n",
            "Epoch 1397: loss 0.37908\n",
            "Epoch 1398: loss 0.37906\n",
            "Epoch 1399: loss 0.37903\n",
            "Epoch 1400: loss 0.37901\n",
            "Epoch 1401: loss 0.37899\n",
            "Epoch 1402: loss 0.37897\n",
            "Epoch 1403: loss 0.37895\n",
            "Epoch 1404: loss 0.37892\n",
            "Epoch 1405: loss 0.37890\n",
            "Epoch 1406: loss 0.37888\n",
            "Epoch 1407: loss 0.37886\n",
            "Epoch 1408: loss 0.37883\n",
            "Epoch 1409: loss 0.37881\n",
            "Epoch 1410: loss 0.37879\n",
            "Epoch 1411: loss 0.37877\n",
            "Epoch 1412: loss 0.37875\n",
            "Epoch 1413: loss 0.37872\n",
            "Epoch 1414: loss 0.37870\n",
            "Epoch 1415: loss 0.37868\n",
            "Epoch 1416: loss 0.37866\n",
            "Epoch 1417: loss 0.37864\n",
            "Epoch 1418: loss 0.37861\n",
            "Epoch 1419: loss 0.37859\n",
            "Epoch 1420: loss 0.37857\n",
            "Epoch 1421: loss 0.37855\n",
            "Epoch 1422: loss 0.37852\n",
            "Epoch 1423: loss 0.37850\n",
            "Epoch 1424: loss 0.37848\n",
            "Epoch 1425: loss 0.37846\n",
            "Epoch 1426: loss 0.37844\n",
            "Epoch 1427: loss 0.37841\n",
            "Epoch 1428: loss 0.37839\n",
            "Epoch 1429: loss 0.37837\n",
            "Epoch 1430: loss 0.37834\n",
            "Epoch 1431: loss 0.37832\n",
            "Epoch 1432: loss 0.37830\n",
            "Epoch 1433: loss 0.37828\n",
            "Epoch 1434: loss 0.37825\n",
            "Epoch 1435: loss 0.37823\n",
            "Epoch 1436: loss 0.37821\n",
            "Epoch 1437: loss 0.37818\n",
            "Epoch 1438: loss 0.37816\n",
            "Epoch 1439: loss 0.37814\n",
            "Epoch 1440: loss 0.37811\n",
            "Epoch 1441: loss 0.37809\n",
            "Epoch 1442: loss 0.37807\n",
            "Epoch 1443: loss 0.37804\n",
            "Epoch 1444: loss 0.37802\n",
            "Epoch 1445: loss 0.37800\n",
            "Epoch 1446: loss 0.37797\n",
            "Epoch 1447: loss 0.37795\n",
            "Epoch 1448: loss 0.37792\n",
            "Epoch 1449: loss 0.37790\n",
            "Epoch 1450: loss 0.37787\n",
            "Epoch 1451: loss 0.37785\n",
            "Epoch 1452: loss 0.37782\n",
            "Epoch 1453: loss 0.37780\n",
            "Epoch 1454: loss 0.37777\n",
            "Epoch 1455: loss 0.37775\n",
            "Epoch 1456: loss 0.37772\n",
            "Epoch 1457: loss 0.37770\n",
            "Epoch 1458: loss 0.37767\n",
            "Epoch 1459: loss 0.37765\n",
            "Epoch 1460: loss 0.37762\n",
            "Epoch 1461: loss 0.37759\n",
            "Epoch 1462: loss 0.37757\n",
            "Epoch 1463: loss 0.37754\n",
            "Epoch 1464: loss 0.37751\n",
            "Epoch 1465: loss 0.37748\n",
            "Epoch 1466: loss 0.37746\n",
            "Epoch 1467: loss 0.37743\n",
            "Epoch 1468: loss 0.37740\n",
            "Epoch 1469: loss 0.37737\n",
            "Epoch 1470: loss 0.37734\n",
            "Epoch 1471: loss 0.37731\n",
            "Epoch 1472: loss 0.37729\n",
            "Epoch 1473: loss 0.37726\n",
            "Epoch 1474: loss 0.37723\n",
            "Epoch 1475: loss 0.37720\n",
            "Epoch 1476: loss 0.37716\n",
            "Epoch 1477: loss 0.37713\n",
            "Epoch 1478: loss 0.37710\n",
            "Epoch 1479: loss 0.37707\n",
            "Epoch 1480: loss 0.37704\n",
            "Epoch 1481: loss 0.37701\n",
            "Epoch 1482: loss 0.37697\n",
            "Epoch 1483: loss 0.37694\n",
            "Epoch 1484: loss 0.37691\n",
            "Epoch 1485: loss 0.37687\n",
            "Epoch 1486: loss 0.37684\n",
            "Epoch 1487: loss 0.37680\n",
            "Epoch 1488: loss 0.37677\n",
            "Epoch 1489: loss 0.37673\n",
            "Epoch 1490: loss 0.37670\n",
            "Epoch 1491: loss 0.37666\n",
            "Epoch 1492: loss 0.37662\n",
            "Epoch 1493: loss 0.37659\n",
            "Epoch 1494: loss 0.37655\n",
            "Epoch 1495: loss 0.37651\n",
            "Epoch 1496: loss 0.37647\n",
            "Epoch 1497: loss 0.37643\n",
            "Epoch 1498: loss 0.37640\n",
            "Epoch 1499: loss 0.37636\n",
            "Epoch 1500: loss 0.37632\n",
            "Epoch 1501: loss 0.37628\n",
            "Epoch 1502: loss 0.37624\n",
            "Epoch 1503: loss 0.37619\n",
            "Epoch 1504: loss 0.37615\n",
            "Epoch 1505: loss 0.37611\n",
            "Epoch 1506: loss 0.37607\n",
            "Epoch 1507: loss 0.37603\n",
            "Epoch 1508: loss 0.37598\n",
            "Epoch 1509: loss 0.37594\n",
            "Epoch 1510: loss 0.37590\n",
            "Epoch 1511: loss 0.37585\n",
            "Epoch 1512: loss 0.37581\n",
            "Epoch 1513: loss 0.37577\n",
            "Epoch 1514: loss 0.37572\n",
            "Epoch 1515: loss 0.37568\n",
            "Epoch 1516: loss 0.37563\n",
            "Epoch 1517: loss 0.37559\n",
            "Epoch 1518: loss 0.37554\n",
            "Epoch 1519: loss 0.37550\n",
            "Epoch 1520: loss 0.37545\n",
            "Epoch 1521: loss 0.37541\n",
            "Epoch 1522: loss 0.37536\n",
            "Epoch 1523: loss 0.37532\n",
            "Epoch 1524: loss 0.37527\n",
            "Epoch 1525: loss 0.37523\n",
            "Epoch 1526: loss 0.37518\n",
            "Epoch 1527: loss 0.37514\n",
            "Epoch 1528: loss 0.37509\n",
            "Epoch 1529: loss 0.37505\n",
            "Epoch 1530: loss 0.37500\n",
            "Epoch 1531: loss 0.37496\n",
            "Epoch 1532: loss 0.37491\n",
            "Epoch 1533: loss 0.37487\n",
            "Epoch 1534: loss 0.37482\n",
            "Epoch 1535: loss 0.37478\n",
            "Epoch 1536: loss 0.37474\n",
            "Epoch 1537: loss 0.37469\n",
            "Epoch 1538: loss 0.37465\n",
            "Epoch 1539: loss 0.37461\n",
            "Epoch 1540: loss 0.37457\n",
            "Epoch 1541: loss 0.37452\n",
            "Epoch 1542: loss 0.37448\n",
            "Epoch 1543: loss 0.37444\n",
            "Epoch 1544: loss 0.37440\n",
            "Epoch 1545: loss 0.37436\n",
            "Epoch 1546: loss 0.37432\n",
            "Epoch 1547: loss 0.37428\n",
            "Epoch 1548: loss 0.37424\n",
            "Epoch 1549: loss 0.37420\n",
            "Epoch 1550: loss 0.37416\n",
            "Epoch 1551: loss 0.37412\n",
            "Epoch 1552: loss 0.37409\n",
            "Epoch 1553: loss 0.37405\n",
            "Epoch 1554: loss 0.37401\n",
            "Epoch 1555: loss 0.37397\n",
            "Epoch 1556: loss 0.37394\n",
            "Epoch 1557: loss 0.37390\n",
            "Epoch 1558: loss 0.37387\n",
            "Epoch 1559: loss 0.37383\n",
            "Epoch 1560: loss 0.37379\n",
            "Epoch 1561: loss 0.37376\n",
            "Epoch 1562: loss 0.37373\n",
            "Epoch 1563: loss 0.37369\n",
            "Epoch 1564: loss 0.37366\n",
            "Epoch 1565: loss 0.37362\n",
            "Epoch 1566: loss 0.37359\n",
            "Epoch 1567: loss 0.37355\n",
            "Epoch 1568: loss 0.37352\n",
            "Epoch 1569: loss 0.37349\n",
            "Epoch 1570: loss 0.37345\n",
            "Epoch 1571: loss 0.37342\n",
            "Epoch 1572: loss 0.37339\n",
            "Epoch 1573: loss 0.37335\n",
            "Epoch 1574: loss 0.37332\n",
            "Epoch 1575: loss 0.37329\n",
            "Epoch 1576: loss 0.37325\n",
            "Epoch 1577: loss 0.37322\n",
            "Epoch 1578: loss 0.37319\n",
            "Epoch 1579: loss 0.37315\n",
            "Epoch 1580: loss 0.37312\n",
            "Epoch 1581: loss 0.37308\n",
            "Epoch 1582: loss 0.37305\n",
            "Epoch 1583: loss 0.37302\n",
            "Epoch 1584: loss 0.37298\n",
            "Epoch 1585: loss 0.37295\n",
            "Epoch 1586: loss 0.37291\n",
            "Epoch 1587: loss 0.37288\n",
            "Epoch 1588: loss 0.37285\n",
            "Epoch 1589: loss 0.37281\n",
            "Epoch 1590: loss 0.37278\n",
            "Epoch 1591: loss 0.37274\n",
            "Epoch 1592: loss 0.37271\n",
            "Epoch 1593: loss 0.37267\n",
            "Epoch 1594: loss 0.37264\n",
            "Epoch 1595: loss 0.37260\n",
            "Epoch 1596: loss 0.37257\n",
            "Epoch 1597: loss 0.37253\n",
            "Epoch 1598: loss 0.37250\n",
            "Epoch 1599: loss 0.37246\n",
            "Epoch 1600: loss 0.37243\n",
            "Epoch 1601: loss 0.37239\n",
            "Epoch 1602: loss 0.37236\n",
            "Epoch 1603: loss 0.37233\n",
            "Epoch 1604: loss 0.37229\n",
            "Epoch 1605: loss 0.37226\n",
            "Epoch 1606: loss 0.37223\n",
            "Epoch 1607: loss 0.37219\n",
            "Epoch 1608: loss 0.37216\n",
            "Epoch 1609: loss 0.37213\n",
            "Epoch 1610: loss 0.37209\n",
            "Epoch 1611: loss 0.37206\n",
            "Epoch 1612: loss 0.37203\n",
            "Epoch 1613: loss 0.37200\n",
            "Epoch 1614: loss 0.37196\n",
            "Epoch 1615: loss 0.37193\n",
            "Epoch 1616: loss 0.37190\n",
            "Epoch 1617: loss 0.37187\n",
            "Epoch 1618: loss 0.37184\n",
            "Epoch 1619: loss 0.37181\n",
            "Epoch 1620: loss 0.37178\n",
            "Epoch 1621: loss 0.37175\n",
            "Epoch 1622: loss 0.37172\n",
            "Epoch 1623: loss 0.37169\n",
            "Epoch 1624: loss 0.37166\n",
            "Epoch 1625: loss 0.37163\n",
            "Epoch 1626: loss 0.37160\n",
            "Epoch 1627: loss 0.37157\n",
            "Epoch 1628: loss 0.37154\n",
            "Epoch 1629: loss 0.37151\n",
            "Epoch 1630: loss 0.37148\n",
            "Epoch 1631: loss 0.37145\n",
            "Epoch 1632: loss 0.37142\n",
            "Epoch 1633: loss 0.37139\n",
            "Epoch 1634: loss 0.37136\n",
            "Epoch 1635: loss 0.37133\n",
            "Epoch 1636: loss 0.37130\n",
            "Epoch 1637: loss 0.37127\n",
            "Epoch 1638: loss 0.37124\n",
            "Epoch 1639: loss 0.37121\n",
            "Epoch 1640: loss 0.37118\n",
            "Epoch 1641: loss 0.37115\n",
            "Epoch 1642: loss 0.37112\n",
            "Epoch 1643: loss 0.37109\n",
            "Epoch 1644: loss 0.37106\n",
            "Epoch 1645: loss 0.37103\n",
            "Epoch 1646: loss 0.37100\n",
            "Epoch 1647: loss 0.37097\n",
            "Epoch 1648: loss 0.37094\n",
            "Epoch 1649: loss 0.37091\n",
            "Epoch 1650: loss 0.37088\n",
            "Epoch 1651: loss 0.37084\n",
            "Epoch 1652: loss 0.37081\n",
            "Epoch 1653: loss 0.37078\n",
            "Epoch 1654: loss 0.37075\n",
            "Epoch 1655: loss 0.37071\n",
            "Epoch 1656: loss 0.37068\n",
            "Epoch 1657: loss 0.37065\n",
            "Epoch 1658: loss 0.37061\n",
            "Epoch 1659: loss 0.37058\n",
            "Epoch 1660: loss 0.37054\n",
            "Epoch 1661: loss 0.37050\n",
            "Epoch 1662: loss 0.37047\n",
            "Epoch 1663: loss 0.37043\n",
            "Epoch 1664: loss 0.37039\n",
            "Epoch 1665: loss 0.37036\n",
            "Epoch 1666: loss 0.37032\n",
            "Epoch 1667: loss 0.37028\n",
            "Epoch 1668: loss 0.37024\n",
            "Epoch 1669: loss 0.37019\n",
            "Epoch 1670: loss 0.37015\n",
            "Epoch 1671: loss 0.37011\n",
            "Epoch 1672: loss 0.37007\n",
            "Epoch 1673: loss 0.37002\n",
            "Epoch 1674: loss 0.36998\n",
            "Epoch 1675: loss 0.36993\n",
            "Epoch 1676: loss 0.36988\n",
            "Epoch 1677: loss 0.36984\n",
            "Epoch 1678: loss 0.36979\n",
            "Epoch 1679: loss 0.36974\n",
            "Epoch 1680: loss 0.36969\n",
            "Epoch 1681: loss 0.36964\n",
            "Epoch 1682: loss 0.36958\n",
            "Epoch 1683: loss 0.36953\n",
            "Epoch 1684: loss 0.36948\n",
            "Epoch 1685: loss 0.36942\n",
            "Epoch 1686: loss 0.36937\n",
            "Epoch 1687: loss 0.36931\n",
            "Epoch 1688: loss 0.36925\n",
            "Epoch 1689: loss 0.36920\n",
            "Epoch 1690: loss 0.36914\n",
            "Epoch 1691: loss 0.36908\n",
            "Epoch 1692: loss 0.36902\n",
            "Epoch 1693: loss 0.36896\n",
            "Epoch 1694: loss 0.36890\n",
            "Epoch 1695: loss 0.36884\n",
            "Epoch 1696: loss 0.36878\n",
            "Epoch 1697: loss 0.36871\n",
            "Epoch 1698: loss 0.36865\n",
            "Epoch 1699: loss 0.36859\n",
            "Epoch 1700: loss 0.36852\n",
            "Epoch 1701: loss 0.36846\n",
            "Epoch 1702: loss 0.36839\n",
            "Epoch 1703: loss 0.36833\n",
            "Epoch 1704: loss 0.36826\n",
            "Epoch 1705: loss 0.36820\n",
            "Epoch 1706: loss 0.36814\n",
            "Epoch 1707: loss 0.36807\n",
            "Epoch 1708: loss 0.36801\n",
            "Epoch 1709: loss 0.36794\n",
            "Epoch 1710: loss 0.36788\n",
            "Epoch 1711: loss 0.36782\n",
            "Epoch 1712: loss 0.36775\n",
            "Epoch 1713: loss 0.36769\n",
            "Epoch 1714: loss 0.36763\n",
            "Epoch 1715: loss 0.36757\n",
            "Epoch 1716: loss 0.36751\n",
            "Epoch 1717: loss 0.36745\n",
            "Epoch 1718: loss 0.36739\n",
            "Epoch 1719: loss 0.36733\n",
            "Epoch 1720: loss 0.36727\n",
            "Epoch 1721: loss 0.36721\n",
            "Epoch 1722: loss 0.36716\n",
            "Epoch 1723: loss 0.36710\n",
            "Epoch 1724: loss 0.36704\n",
            "Epoch 1725: loss 0.36699\n",
            "Epoch 1726: loss 0.36693\n",
            "Epoch 1727: loss 0.36687\n",
            "Epoch 1728: loss 0.36682\n",
            "Epoch 1729: loss 0.36677\n",
            "Epoch 1730: loss 0.36671\n",
            "Epoch 1731: loss 0.36666\n",
            "Epoch 1732: loss 0.36661\n",
            "Epoch 1733: loss 0.36655\n",
            "Epoch 1734: loss 0.36650\n",
            "Epoch 1735: loss 0.36645\n",
            "Epoch 1736: loss 0.36640\n",
            "Epoch 1737: loss 0.36635\n",
            "Epoch 1738: loss 0.36630\n",
            "Epoch 1739: loss 0.36625\n",
            "Epoch 1740: loss 0.36620\n",
            "Epoch 1741: loss 0.36615\n",
            "Epoch 1742: loss 0.36610\n",
            "Epoch 1743: loss 0.36605\n",
            "Epoch 1744: loss 0.36601\n",
            "Epoch 1745: loss 0.36596\n",
            "Epoch 1746: loss 0.36591\n",
            "Epoch 1747: loss 0.36587\n",
            "Epoch 1748: loss 0.36582\n",
            "Epoch 1749: loss 0.36577\n",
            "Epoch 1750: loss 0.36573\n",
            "Epoch 1751: loss 0.36568\n",
            "Epoch 1752: loss 0.36564\n",
            "Epoch 1753: loss 0.36559\n",
            "Epoch 1754: loss 0.36555\n",
            "Epoch 1755: loss 0.36551\n",
            "Epoch 1756: loss 0.36546\n",
            "Epoch 1757: loss 0.36542\n",
            "Epoch 1758: loss 0.36538\n",
            "Epoch 1759: loss 0.36533\n",
            "Epoch 1760: loss 0.36529\n",
            "Epoch 1761: loss 0.36525\n",
            "Epoch 1762: loss 0.36521\n",
            "Epoch 1763: loss 0.36517\n",
            "Epoch 1764: loss 0.36513\n",
            "Epoch 1765: loss 0.36508\n",
            "Epoch 1766: loss 0.36504\n",
            "Epoch 1767: loss 0.36500\n",
            "Epoch 1768: loss 0.36496\n",
            "Epoch 1769: loss 0.36492\n",
            "Epoch 1770: loss 0.36488\n",
            "Epoch 1771: loss 0.36484\n",
            "Epoch 1772: loss 0.36480\n",
            "Epoch 1773: loss 0.36477\n",
            "Epoch 1774: loss 0.36473\n",
            "Epoch 1775: loss 0.36469\n",
            "Epoch 1776: loss 0.36465\n",
            "Epoch 1777: loss 0.36461\n",
            "Epoch 1778: loss 0.36457\n",
            "Epoch 1779: loss 0.36454\n",
            "Epoch 1780: loss 0.36450\n",
            "Epoch 1781: loss 0.36446\n",
            "Epoch 1782: loss 0.36442\n",
            "Epoch 1783: loss 0.36439\n",
            "Epoch 1784: loss 0.36435\n",
            "Epoch 1785: loss 0.36431\n",
            "Epoch 1786: loss 0.36428\n",
            "Epoch 1787: loss 0.36424\n",
            "Epoch 1788: loss 0.36420\n",
            "Epoch 1789: loss 0.36417\n",
            "Epoch 1790: loss 0.36413\n",
            "Epoch 1791: loss 0.36410\n",
            "Epoch 1792: loss 0.36406\n",
            "Epoch 1793: loss 0.36403\n",
            "Epoch 1794: loss 0.36399\n",
            "Epoch 1795: loss 0.36395\n",
            "Epoch 1796: loss 0.36392\n",
            "Epoch 1797: loss 0.36388\n",
            "Epoch 1798: loss 0.36385\n",
            "Epoch 1799: loss 0.36381\n",
            "Epoch 1800: loss 0.36378\n",
            "Epoch 1801: loss 0.36375\n",
            "Epoch 1802: loss 0.36371\n",
            "Epoch 1803: loss 0.36368\n",
            "Epoch 1804: loss 0.36364\n",
            "Epoch 1805: loss 0.36361\n",
            "Epoch 1806: loss 0.36357\n",
            "Epoch 1807: loss 0.36354\n",
            "Epoch 1808: loss 0.36351\n",
            "Epoch 1809: loss 0.36347\n",
            "Epoch 1810: loss 0.36344\n",
            "Epoch 1811: loss 0.36341\n",
            "Epoch 1812: loss 0.36337\n",
            "Epoch 1813: loss 0.36334\n",
            "Epoch 1814: loss 0.36330\n",
            "Epoch 1815: loss 0.36327\n",
            "Epoch 1816: loss 0.36324\n",
            "Epoch 1817: loss 0.36321\n",
            "Epoch 1818: loss 0.36317\n",
            "Epoch 1819: loss 0.36314\n",
            "Epoch 1820: loss 0.36311\n",
            "Epoch 1821: loss 0.36307\n",
            "Epoch 1822: loss 0.36304\n",
            "Epoch 1823: loss 0.36301\n",
            "Epoch 1824: loss 0.36297\n",
            "Epoch 1825: loss 0.36294\n",
            "Epoch 1826: loss 0.36291\n",
            "Epoch 1827: loss 0.36288\n",
            "Epoch 1828: loss 0.36284\n",
            "Epoch 1829: loss 0.36281\n",
            "Epoch 1830: loss 0.36278\n",
            "Epoch 1831: loss 0.36275\n",
            "Epoch 1832: loss 0.36272\n",
            "Epoch 1833: loss 0.36268\n",
            "Epoch 1834: loss 0.36265\n",
            "Epoch 1835: loss 0.36262\n",
            "Epoch 1836: loss 0.36259\n",
            "Epoch 1837: loss 0.36256\n",
            "Epoch 1838: loss 0.36252\n",
            "Epoch 1839: loss 0.36249\n",
            "Epoch 1840: loss 0.36246\n",
            "Epoch 1841: loss 0.36243\n",
            "Epoch 1842: loss 0.36240\n",
            "Epoch 1843: loss 0.36237\n",
            "Epoch 1844: loss 0.36233\n",
            "Epoch 1845: loss 0.36230\n",
            "Epoch 1846: loss 0.36227\n",
            "Epoch 1847: loss 0.36224\n",
            "Epoch 1848: loss 0.36221\n",
            "Epoch 1849: loss 0.36218\n",
            "Epoch 1850: loss 0.36215\n",
            "Epoch 1851: loss 0.36212\n",
            "Epoch 1852: loss 0.36209\n",
            "Epoch 1853: loss 0.36206\n",
            "Epoch 1854: loss 0.36202\n",
            "Epoch 1855: loss 0.36199\n",
            "Epoch 1856: loss 0.36196\n",
            "Epoch 1857: loss 0.36193\n",
            "Epoch 1858: loss 0.36190\n",
            "Epoch 1859: loss 0.36187\n",
            "Epoch 1860: loss 0.36184\n",
            "Epoch 1861: loss 0.36181\n",
            "Epoch 1862: loss 0.36178\n",
            "Epoch 1863: loss 0.36175\n",
            "Epoch 1864: loss 0.36172\n",
            "Epoch 1865: loss 0.36169\n",
            "Epoch 1866: loss 0.36166\n",
            "Epoch 1867: loss 0.36163\n",
            "Epoch 1868: loss 0.36160\n",
            "Epoch 1869: loss 0.36157\n",
            "Epoch 1870: loss 0.36154\n",
            "Epoch 1871: loss 0.36151\n",
            "Epoch 1872: loss 0.36148\n",
            "Epoch 1873: loss 0.36145\n",
            "Epoch 1874: loss 0.36142\n",
            "Epoch 1875: loss 0.36139\n",
            "Epoch 1876: loss 0.36136\n",
            "Epoch 1877: loss 0.36133\n",
            "Epoch 1878: loss 0.36130\n",
            "Epoch 1879: loss 0.36127\n",
            "Epoch 1880: loss 0.36124\n",
            "Epoch 1881: loss 0.36121\n",
            "Epoch 1882: loss 0.36118\n",
            "Epoch 1883: loss 0.36115\n",
            "Epoch 1884: loss 0.36112\n",
            "Epoch 1885: loss 0.36109\n",
            "Epoch 1886: loss 0.36106\n",
            "Epoch 1887: loss 0.36103\n",
            "Epoch 1888: loss 0.36100\n",
            "Epoch 1889: loss 0.36097\n",
            "Epoch 1890: loss 0.36094\n",
            "Epoch 1891: loss 0.36091\n",
            "Epoch 1892: loss 0.36088\n",
            "Epoch 1893: loss 0.36085\n",
            "Epoch 1894: loss 0.36082\n",
            "Epoch 1895: loss 0.36079\n",
            "Epoch 1896: loss 0.36076\n",
            "Epoch 1897: loss 0.36073\n",
            "Epoch 1898: loss 0.36070\n",
            "Epoch 1899: loss 0.36067\n",
            "Epoch 1900: loss 0.36064\n",
            "Epoch 1901: loss 0.36061\n",
            "Epoch 1902: loss 0.36058\n",
            "Epoch 1903: loss 0.36055\n",
            "Epoch 1904: loss 0.36052\n",
            "Epoch 1905: loss 0.36049\n",
            "Epoch 1906: loss 0.36046\n",
            "Epoch 1907: loss 0.36043\n",
            "Epoch 1908: loss 0.36040\n",
            "Epoch 1909: loss 0.36037\n",
            "Epoch 1910: loss 0.36034\n",
            "Epoch 1911: loss 0.36031\n",
            "Epoch 1912: loss 0.36028\n",
            "Epoch 1913: loss 0.36025\n",
            "Epoch 1914: loss 0.36022\n",
            "Epoch 1915: loss 0.36018\n",
            "Epoch 1916: loss 0.36015\n",
            "Epoch 1917: loss 0.36012\n",
            "Epoch 1918: loss 0.36009\n",
            "Epoch 1919: loss 0.36006\n",
            "Epoch 1920: loss 0.36003\n",
            "Epoch 1921: loss 0.36000\n",
            "Epoch 1922: loss 0.35997\n",
            "Epoch 1923: loss 0.35993\n",
            "Epoch 1924: loss 0.35990\n",
            "Epoch 1925: loss 0.35987\n",
            "Epoch 1926: loss 0.35984\n",
            "Epoch 1927: loss 0.35981\n",
            "Epoch 1928: loss 0.35978\n",
            "Epoch 1929: loss 0.35974\n",
            "Epoch 1930: loss 0.35971\n",
            "Epoch 1931: loss 0.35968\n",
            "Epoch 1932: loss 0.35965\n",
            "Epoch 1933: loss 0.35961\n",
            "Epoch 1934: loss 0.35958\n",
            "Epoch 1935: loss 0.35955\n",
            "Epoch 1936: loss 0.35952\n",
            "Epoch 1937: loss 0.35949\n",
            "Epoch 1938: loss 0.35945\n",
            "Epoch 1939: loss 0.35942\n",
            "Epoch 1940: loss 0.35939\n",
            "Epoch 1941: loss 0.35936\n",
            "Epoch 1942: loss 0.35932\n",
            "Epoch 1943: loss 0.35929\n",
            "Epoch 1944: loss 0.35926\n",
            "Epoch 1945: loss 0.35922\n",
            "Epoch 1946: loss 0.35919\n",
            "Epoch 1947: loss 0.35916\n",
            "Epoch 1948: loss 0.35912\n",
            "Epoch 1949: loss 0.35909\n",
            "Epoch 1950: loss 0.35906\n",
            "Epoch 1951: loss 0.35903\n",
            "Epoch 1952: loss 0.35899\n",
            "Epoch 1953: loss 0.35896\n",
            "Epoch 1954: loss 0.35893\n",
            "Epoch 1955: loss 0.35889\n",
            "Epoch 1956: loss 0.35886\n",
            "Epoch 1957: loss 0.35883\n",
            "Epoch 1958: loss 0.35879\n",
            "Epoch 1959: loss 0.35876\n",
            "Epoch 1960: loss 0.35873\n",
            "Epoch 1961: loss 0.35869\n",
            "Epoch 1962: loss 0.35866\n",
            "Epoch 1963: loss 0.35862\n",
            "Epoch 1964: loss 0.35859\n",
            "Epoch 1965: loss 0.35856\n",
            "Epoch 1966: loss 0.35852\n",
            "Epoch 1967: loss 0.35849\n",
            "Epoch 1968: loss 0.35846\n",
            "Epoch 1969: loss 0.35842\n",
            "Epoch 1970: loss 0.35839\n",
            "Epoch 1971: loss 0.35836\n",
            "Epoch 1972: loss 0.35832\n",
            "Epoch 1973: loss 0.35829\n",
            "Epoch 1974: loss 0.35826\n",
            "Epoch 1975: loss 0.35822\n",
            "Epoch 1976: loss 0.35819\n",
            "Epoch 1977: loss 0.35815\n",
            "Epoch 1978: loss 0.35812\n",
            "Epoch 1979: loss 0.35809\n",
            "Epoch 1980: loss 0.35805\n",
            "Epoch 1981: loss 0.35802\n",
            "Epoch 1982: loss 0.35799\n",
            "Epoch 1983: loss 0.35795\n",
            "Epoch 1984: loss 0.35792\n",
            "Epoch 1985: loss 0.35789\n",
            "Epoch 1986: loss 0.35785\n",
            "Epoch 1987: loss 0.35782\n",
            "Epoch 1988: loss 0.35779\n",
            "Epoch 1989: loss 0.35775\n",
            "Epoch 1990: loss 0.35772\n",
            "Epoch 1991: loss 0.35768\n",
            "Epoch 1992: loss 0.35765\n",
            "Epoch 1993: loss 0.35762\n",
            "Epoch 1994: loss 0.35758\n",
            "Epoch 1995: loss 0.35755\n",
            "Epoch 1996: loss 0.35752\n",
            "Epoch 1997: loss 0.35748\n",
            "Epoch 1998: loss 0.35745\n",
            "Epoch 1999: loss 0.35742\n",
            "Epoch 2000: loss 0.35739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyTjLzELSdQF"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZafmlssFs5SG",
        "outputId": "e03f4ca4-ea48-4acc-dfa1-e34eae1d99a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "network.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=8, out_features=5, bias=True)\n",
              "  (1): Sigmoid()\n",
              "  (2): Linear(in_features=5, out_features=5, bias=True)\n",
              "  (3): Sigmoid()\n",
              "  (4): Linear(in_features=5, out_features=1, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuL49MUEtOrh"
      },
      "source": [
        "X_test = torch.tensor(X_test, dtype=torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe8muTxbtc1G"
      },
      "source": [
        "predictions = network.forward(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn0leHiAtqpx",
        "outputId": "2878585e-cb40-4faa-e1e5-7fed888884d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.3385e-01],\n",
              "        [5.7871e-05],\n",
              "        [1.7082e-03],\n",
              "        [9.2858e-02],\n",
              "        [7.0913e-02],\n",
              "        [3.1133e-10],\n",
              "        [7.5009e-02],\n",
              "        [4.6715e-12],\n",
              "        [3.1668e-01],\n",
              "        [1.9531e-02],\n",
              "        [2.1147e-02],\n",
              "        [2.7166e-05],\n",
              "        [6.0122e-02],\n",
              "        [9.9805e-01],\n",
              "        [7.4418e-02],\n",
              "        [1.0000e+00],\n",
              "        [8.1108e-02],\n",
              "        [5.5402e-02],\n",
              "        [4.2759e-02],\n",
              "        [9.9896e-01],\n",
              "        [4.4112e-01],\n",
              "        [3.5185e-12],\n",
              "        [1.8015e-10],\n",
              "        [5.3125e-01],\n",
              "        [1.4124e-02],\n",
              "        [1.1748e-01],\n",
              "        [3.5952e-01],\n",
              "        [1.0000e+00],\n",
              "        [3.9829e-10],\n",
              "        [8.5593e-02],\n",
              "        [9.5009e-02],\n",
              "        [1.2685e-05],\n",
              "        [4.4221e-01],\n",
              "        [4.9865e-07],\n",
              "        [4.9165e-01],\n",
              "        [4.9207e-01],\n",
              "        [3.5116e-03],\n",
              "        [3.8976e-01],\n",
              "        [1.0000e+00],\n",
              "        [7.8162e-02],\n",
              "        [4.9718e-01],\n",
              "        [5.3923e-01],\n",
              "        [4.8077e-01],\n",
              "        [9.9438e-01],\n",
              "        [3.0056e-02],\n",
              "        [4.1430e-01],\n",
              "        [4.6704e-01],\n",
              "        [6.0950e-02],\n",
              "        [4.0913e-01],\n",
              "        [9.6327e-02],\n",
              "        [4.6669e-01],\n",
              "        [7.8620e-01],\n",
              "        [8.8592e-02],\n",
              "        [1.4616e-01],\n",
              "        [5.8223e-05],\n",
              "        [7.0114e-01],\n",
              "        [6.8873e-01],\n",
              "        [4.8311e-01],\n",
              "        [2.2590e-01],\n",
              "        [3.6907e-02],\n",
              "        [6.4069e-02],\n",
              "        [4.2540e-01],\n",
              "        [4.1086e-01],\n",
              "        [3.9404e-01],\n",
              "        [2.1608e-06],\n",
              "        [8.6573e-02],\n",
              "        [4.3069e-01],\n",
              "        [9.9814e-01],\n",
              "        [4.6425e-03],\n",
              "        [7.2996e-01],\n",
              "        [9.7558e-02],\n",
              "        [2.4211e-02],\n",
              "        [2.6962e-06],\n",
              "        [7.0933e-02],\n",
              "        [4.7333e-01],\n",
              "        [9.6225e-01],\n",
              "        [5.2570e-02],\n",
              "        [8.4197e-04],\n",
              "        [4.6718e-01],\n",
              "        [4.6512e-01],\n",
              "        [7.3280e-02],\n",
              "        [1.0676e-01],\n",
              "        [1.0000e+00],\n",
              "        [3.4136e-01],\n",
              "        [8.1948e-02],\n",
              "        [8.5599e-01],\n",
              "        [6.1794e-01],\n",
              "        [9.9999e-01],\n",
              "        [4.6440e-01],\n",
              "        [9.4308e-01],\n",
              "        [5.2074e-02],\n",
              "        [2.0569e-07],\n",
              "        [7.9361e-02],\n",
              "        [8.2948e-02],\n",
              "        [2.0472e-02],\n",
              "        [3.9967e-01],\n",
              "        [2.1791e-01],\n",
              "        [4.6087e-01],\n",
              "        [8.3967e-01],\n",
              "        [9.9414e-01],\n",
              "        [8.7775e-02],\n",
              "        [4.3383e-01],\n",
              "        [7.8211e-02],\n",
              "        [4.5277e-01],\n",
              "        [1.0651e-01],\n",
              "        [1.7678e-02],\n",
              "        [2.7644e-07],\n",
              "        [7.9386e-02],\n",
              "        [1.9826e-06],\n",
              "        [1.6449e-03],\n",
              "        [5.3516e-02],\n",
              "        [6.7563e-02],\n",
              "        [1.4394e-01],\n",
              "        [9.9879e-01],\n",
              "        [4.0066e-01],\n",
              "        [9.5407e-02],\n",
              "        [5.8312e-10],\n",
              "        [9.1750e-02],\n",
              "        [8.5930e-02],\n",
              "        [1.9967e-01],\n",
              "        [6.3252e-01],\n",
              "        [6.8938e-02],\n",
              "        [2.8835e-01],\n",
              "        [8.0951e-03],\n",
              "        [1.4538e-01],\n",
              "        [1.1277e-03],\n",
              "        [4.5423e-01],\n",
              "        [3.7299e-01],\n",
              "        [9.8862e-01],\n",
              "        [4.5580e-01],\n",
              "        [1.0428e-01],\n",
              "        [6.0331e-06],\n",
              "        [1.0199e-01],\n",
              "        [4.7422e-01],\n",
              "        [1.0000e+00],\n",
              "        [4.1992e-01],\n",
              "        [3.3545e-01],\n",
              "        [3.6179e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.3152e-01],\n",
              "        [5.5085e-07],\n",
              "        [1.3878e-01],\n",
              "        [4.6261e-02],\n",
              "        [5.9662e-01],\n",
              "        [8.9121e-02],\n",
              "        [8.6849e-02],\n",
              "        [5.1723e-08],\n",
              "        [5.0826e-02],\n",
              "        [4.8780e-01],\n",
              "        [3.8329e-02],\n",
              "        [8.9351e-02],\n",
              "        [1.3688e-02],\n",
              "        [9.9998e-01],\n",
              "        [4.4756e-01]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu8CV7XawV_K",
        "outputId": "d4c96243-f74d-49e3-d87e-b293a5bf7c8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "predictions = (predictions >= 0.5)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVPFTbGeuSU5",
        "outputId": "690cd7b8-d1b8-4fd7-b33b-ee2702df8a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7jfnFtZuNVn",
        "outputId": "9a20d02a-a388-4c66-aa65-c69d05a861ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(y_test, predictions.detach().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7337662337662337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYLq3Y7ctnbS",
        "outputId": "ee20a9ba-6f61-4a51-de06-8a846e148918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "cm = confusion_matrix(y_test, predictions.detach().numpy())\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[92,  8],\n",
              "       [33, 21]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3C7dimytqG6",
        "outputId": "843a8db1-3dc8-4934-c949-893fc509352a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb6fdad96a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}