{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Datasets Building\n",
    "class DiabetesDataset(Dataset):\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        self.data_original = np.loadtxt(filepath, skiprows=1, delimiter=',')\n",
    "        self.len = self.data_original[0]\n",
    "        self.x_data = torch.Tensor(self.data_original[:, :-1])\n",
    "        self.y_data = torch.Tensor(self.data_original[:, [-1]])\n",
    "        self.x_train = None\n",
    "        self.y_train = None\n",
    "        self.x_valid = None\n",
    "        self.y_valid = None\n",
    "        self.x_test = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def data_split(self, train_size, valid_size, test_size):\n",
    "        train, valid, test = random_split(self.data_original, [train_size, valid_size, test_size])\n",
    "        self.x_train, self.y_train = torch.Tensor(train[:, :-1]), torch.Tensor(train[:, [-1]])\n",
    "        self.x_valid, self.y_valid = torch.Tensor(valid[:, :-1]), torch.Tensor(valid[:, [-1]])\n",
    "        self.x_test, self.y_test = torch.Tensor(test[:, :-1]), torch.Tensor(test[:, [-1]])\n",
    "        return \n",
    "\n",
    "\n",
    "file = 'pima_indians_diabetes.csv'\n",
    "mydataset = DiabetesDataset(file)\n",
    "# mydataset.data_split(train_size=0.8, valid_size=0.1, test_size=0.1)\n",
    "# mydataset.x_train.shape\n",
    "# trainloader = DataLoader(dataset=TensorDataset(mydataset.x_train,mydataset.y_train), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, dim1, dim2):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(8, dim1, bias=False)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(dim1, dim2)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(dim2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.linear1(x)\n",
    "        output = self.activation1(output)\n",
    "        output = self.linear2(output)\n",
    "        output = self.activation2(output)\n",
    "        output = self.linear3(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "    \n",
    "model = MyModel(64, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Model\n",
    "class ANN_model(nn.Module):\n",
    "    def __init__(self,input_features=8,hidden1=20, hidden2=10,out_features=1):\n",
    "        super().__init__()\n",
    "        self.f_connected1 = nn.Linear(input_features,hidden1)\n",
    "        self.f_connected2 = nn.Linear(hidden1,hidden2)\n",
    "        self.out = nn.Linear(hidden2,out_features)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.f_connected1(x))\n",
    "        x = F.relu(self.f_connected2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "model = ANN_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1 and the loss : -0.0\n",
      "Epoch number: 11 and the loss : -0.0\n",
      "Epoch number: 21 and the loss : -0.0\n",
      "Epoch number: 31 and the loss : -0.0\n",
      "Epoch number: 41 and the loss : -0.0\n",
      "Epoch number: 51 and the loss : -0.0\n",
      "Epoch number: 61 and the loss : -0.0\n",
      "Epoch number: 71 and the loss : -0.0\n",
      "Epoch number: 81 and the loss : -0.0\n",
      "Epoch number: 91 and the loss : -0.0\n",
      "Epoch number: 101 and the loss : -0.0\n",
      "Epoch number: 111 and the loss : -0.0\n",
      "Epoch number: 121 and the loss : -0.0\n",
      "Epoch number: 131 and the loss : -0.0\n",
      "Epoch number: 141 and the loss : -0.0\n",
      "Epoch number: 151 and the loss : -0.0\n",
      "Epoch number: 161 and the loss : -0.0\n",
      "Epoch number: 171 and the loss : -0.0\n",
      "Epoch number: 181 and the loss : -0.0\n",
      "Epoch number: 191 and the loss : -0.0\n",
      "Epoch number: 201 and the loss : -0.0\n",
      "Epoch number: 211 and the loss : -0.0\n",
      "Epoch number: 221 and the loss : -0.0\n",
      "Epoch number: 231 and the loss : -0.0\n",
      "Epoch number: 241 and the loss : -0.0\n",
      "Epoch number: 251 and the loss : -0.0\n",
      "Epoch number: 261 and the loss : -0.0\n",
      "Epoch number: 271 and the loss : -0.0\n",
      "Epoch number: 281 and the loss : -0.0\n",
      "Epoch number: 291 and the loss : -0.0\n",
      "Epoch number: 301 and the loss : -0.0\n",
      "Epoch number: 311 and the loss : -0.0\n",
      "Epoch number: 321 and the loss : -0.0\n",
      "Epoch number: 331 and the loss : -0.0\n",
      "Epoch number: 341 and the loss : -0.0\n",
      "Epoch number: 351 and the loss : -0.0\n",
      "Epoch number: 361 and the loss : -0.0\n",
      "Epoch number: 371 and the loss : -0.0\n",
      "Epoch number: 381 and the loss : -0.0\n",
      "Epoch number: 391 and the loss : -0.0\n",
      "Epoch number: 401 and the loss : -0.0\n",
      "Epoch number: 411 and the loss : -0.0\n",
      "Epoch number: 421 and the loss : -0.0\n",
      "Epoch number: 431 and the loss : -0.0\n",
      "Epoch number: 441 and the loss : -0.0\n",
      "Epoch number: 451 and the loss : -0.0\n",
      "Epoch number: 461 and the loss : -0.0\n",
      "Epoch number: 471 and the loss : -0.0\n",
      "Epoch number: 481 and the loss : -0.0\n",
      "Epoch number: 491 and the loss : -0.0\n"
     ]
    }
   ],
   "source": [
    "epochs=500\n",
    "final_losses=[]\n",
    "for i in range(epochs):\n",
    "    i= i+1\n",
    "    y_pred=model.forward(mydataset.x_data)\n",
    "    loss=loss_fn(y_pred,mydataset.y_data)\n",
    "    final_losses.append(loss)\n",
    "    if i % 10 == 1:\n",
    "        print(\"Epoch number: {} and the loss : {}\".format(i,loss.item()))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#plot the loss function\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39;49mplot(\u001b[39mrange\u001b[39;49m(epochs),final_losses)\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mEpochs\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Xinxie Wu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\pyplot.py:2740\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2738\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   2739\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2740\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39mplot(\n\u001b[0;32m   2741\u001b[0m         \u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39mscalex, scaley\u001b[39m=\u001b[39mscaley,\n\u001b[0;32m   2742\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Xinxie Wu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1662\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1420\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1421\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1659\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1661\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> 1662\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1663\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   1664\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\Xinxie Wu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(\n\u001b[0;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[39m=\u001b[39;49mambiguous_fmt_datakey)\n",
      "File \u001b[1;32mc:\\Users\\Xinxie Wu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_base.py:494\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(xy) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    493\u001b[0m     x \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m0\u001b[39m])\n\u001b[1;32m--> 494\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m1\u001b[39;49m])\n\u001b[0;32m    495\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m     x, y \u001b[39m=\u001b[39m index_of(xy[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Xinxie Wu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1382\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[39m# plot requires `shape` and `ndim`.  If passed an\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m \u001b[39m# object that doesn't provide them, then force to numpy array.\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m \u001b[39m# Note this will strip unit information.\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1380\u001b[0m         \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1381\u001b[0m         \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m-> 1382\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49matleast_1d(x)\n\u001b[0;32m   1383\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1384\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Xinxie Wu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m     63\u001b[0m res \u001b[39m=\u001b[39m []\n\u001b[0;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m ary \u001b[39min\u001b[39;00m arys:\n\u001b[1;32m---> 65\u001b[0m     ary \u001b[39m=\u001b[39m asanyarray(ary)\n\u001b[0;32m     66\u001b[0m     \u001b[39mif\u001b[39;00m ary\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     67\u001b[0m         result \u001b[39m=\u001b[39m ary\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Xinxie Wu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:970\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    969\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 970\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    971\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    972\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the loss function\n",
    "plt.plot(range(epochs),final_losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.ylabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected floating point type for target with class probabilities, got Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m a, (x,y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trainloader):\n\u001b[0;32m      5\u001b[0m     pred \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m----> 6\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(pred, y)\n\u001b[0;32m      7\u001b[0m     final_loss\u001b[39m.\u001b[39mappend(loss)\n\u001b[0;32m      8\u001b[0m     \u001b[39mif\u001b[39;00m a\u001b[39m%\u001b[39m\u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Xinxie Wu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Xinxie Wu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32mc:\\Users\\Xinxie Wu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected floating point type for target with class probabilities, got Long"
     ]
    }
   ],
   "source": [
    "Epochs = 500    \n",
    "final_loss = []\n",
    "for epoch in range(Epochs):\n",
    "    for a, (x,y) in enumerate(trainloader):\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        final_loss.append(loss)\n",
    "        if a%10 == 1:\n",
    "            print(\"Epoch number: {} and the loss : {}\".format(a,loss.item()))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_loss = [i.detach().numpy() for i in final_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " array(-0., dtype=float32),\n",
       " ...]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (500,) and (12000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39;49mplot(\u001b[39mrange\u001b[39;49m(Epochs),final_loss)\n\u001b[0;32m      2\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mEpochs\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Xinxie Wu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\pyplot.py:2740\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2738\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   2739\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2740\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39mplot(\n\u001b[0;32m   2741\u001b[0m         \u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39mscalex, scaley\u001b[39m=\u001b[39mscaley,\n\u001b[0;32m   2742\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Xinxie Wu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1662\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1420\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1421\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1659\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1661\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> 1662\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1663\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   1664\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\Xinxie Wu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(\n\u001b[0;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[39m=\u001b[39;49mambiguous_fmt_datakey)\n",
      "File \u001b[1;32mc:\\Users\\Xinxie Wu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39mupdate_units(y)\n\u001b[0;32m    503\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m--> 504\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y must have same first dimension, but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhave shapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    506\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y can be no greater than 2D, but have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (500,) and (12000,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(Epochs),final_loss)\n",
    "plt.ylabel('Loss')\n",
    "plt.ylabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Datasets\n",
    "df_tensor = torch.Tensor(df.values)\n",
    "x_tensor = torch.Tensor(x.values)\n",
    "y_tensor = torch.Tensor(y.values)\n",
    "x_train_tensor = torch.Tensor(x_train.values)\n",
    "y_train_tensor = torch.Tensor(y_train.values)\n",
    "x_test_tensor = torch.Tensor(x_test.values)\n",
    "y_test_tensor = torch.Tensor(y_test.values)\n",
    "# df_tensor = torch.Tensor(torch.from_numpy(df.to_numpy()))\n",
    "# x_tensor = torch.DoubleTensor(torch.from_numpy(x.to_numpy()))\n",
    "# y_tensor = torch.LongTensor(torch.from_numpy(y.to_numpy()))\n",
    "# x_train_tensor = torch.DoubleTensor(torch.from_numpy(x_train.to_numpy()))\n",
    "# y_train_tensor = torch.LongTensor(torch.from_numpy(y_train.to_numpy()))\n",
    "# x_test_tensor = torch.DoubleTensor(torch.from_numpy(x_test.to_numpy()))\n",
    "# y_test_tensor = torch.LongTensor(torch.from_numpy(y_test.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(TensorDataset(x_train_tensor, y_train_tensor), batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, dim1, dim2):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(8, dim1, bias=False)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(dim1, dim2)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(dim2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.linear1(x)\n",
    "        output = self.activation1(output)\n",
    "        output = self.linear2(output)\n",
    "        output = self.activation2(output)\n",
    "        output = self.linear3(output)\n",
    "        return output\n",
    "    \n",
    "model = MyModel(64, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n",
      "tensor(-0., grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for a, (x,y) in enumerate(trainloader):\n",
    "    pred = model(x)\n",
    "    # print(pred)\n",
    "    loss = loss_fn(pred, y)\n",
    "    if a%10 == 0:\n",
    "        print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Sigmoid.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m pred \u001b[39m=\u001b[39m model(x_test_tensor)\n\u001b[1;32m----> 3\u001b[0m sigmoid \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mSigmoid(pred)\n\u001b[0;32m      4\u001b[0m pred \u001b[39m=\u001b[39m sigmoid(pred)\n\u001b[0;32m      5\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax\n",
      "File \u001b[1;32mc:\\Users\\wxx19\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:449\u001b[0m, in \u001b[0;36mModule.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.__init__() got an unexpected keyword argument \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(kwargs))))\n\u001b[0;32m    448\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_super_init \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mbool\u001b[39m(args):\n\u001b[1;32m--> 449\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.__init__() takes 1 positional argument but \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m were\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    450\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m given\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39mlen\u001b[39m(args) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[0;32m    452\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39mCalls super().__setattr__('a', a) instead of the typical self.a = a\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39mto avoid Module.__setattr__ overhead. Module's __setattr__ has special\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39mhandling for parameters, submodules, and buffers but simply calls into\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[39msuper().__setattr__ for all other attributes.\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Sigmoid.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "pred = model(x_test_tensor)\n",
    "sigmoid = nn.Sigmoid(pred)\n",
    "pred = sigmoid(pred)\n",
    "result = np.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2824],\n",
       "        [-0.3201],\n",
       "        [-0.3150],\n",
       "        [-0.3372],\n",
       "        [-0.3173],\n",
       "        [-0.2499],\n",
       "        [-0.3576],\n",
       "        [-0.3104],\n",
       "        [-0.2772],\n",
       "        [-0.2491],\n",
       "        [-0.3099],\n",
       "        [-0.2342],\n",
       "        [-0.2888],\n",
       "        [-0.2978],\n",
       "        [-0.3267],\n",
       "        [-0.2924],\n",
       "        [-0.3020],\n",
       "        [-0.3297],\n",
       "        [-0.2868],\n",
       "        [-0.2922],\n",
       "        [-0.2916],\n",
       "        [-0.3344],\n",
       "        [-0.2162],\n",
       "        [-0.3118],\n",
       "        [-0.3196],\n",
       "        [-0.2784],\n",
       "        [-0.3070],\n",
       "        [-0.3596],\n",
       "        [-0.2728],\n",
       "        [-0.3313],\n",
       "        [-0.2837],\n",
       "        [-0.2274],\n",
       "        [-0.2405],\n",
       "        [-0.3204],\n",
       "        [-0.2642],\n",
       "        [-0.2759],\n",
       "        [-0.1793],\n",
       "        [-0.3172],\n",
       "        [-0.2917],\n",
       "        [-0.2969],\n",
       "        [-0.3277],\n",
       "        [-0.2445],\n",
       "        [-0.2282],\n",
       "        [-0.3312],\n",
       "        [-0.3571],\n",
       "        [-0.2588],\n",
       "        [-0.3133],\n",
       "        [-0.2841],\n",
       "        [-0.2706],\n",
       "        [-0.3021],\n",
       "        [-0.3428],\n",
       "        [-0.3001],\n",
       "        [-0.2845],\n",
       "        [-0.3280],\n",
       "        [-0.3369],\n",
       "        [-0.3405],\n",
       "        [-0.2364],\n",
       "        [-0.3250],\n",
       "        [-0.3082],\n",
       "        [-0.2842],\n",
       "        [-0.2795],\n",
       "        [-0.3080],\n",
       "        [-0.3433],\n",
       "        [-0.3332],\n",
       "        [-0.3083],\n",
       "        [-0.2601],\n",
       "        [-0.3379],\n",
       "        [-0.2699],\n",
       "        [-0.3536],\n",
       "        [-0.2107],\n",
       "        [-0.2717],\n",
       "        [-0.3468],\n",
       "        [-0.2701],\n",
       "        [-0.3290],\n",
       "        [-0.3382],\n",
       "        [-0.2158],\n",
       "        [-0.2918],\n",
       "        [-0.3311],\n",
       "        [-0.2857],\n",
       "        [-0.3296],\n",
       "        [-0.2944],\n",
       "        [-0.3340],\n",
       "        [-0.3326],\n",
       "        [-0.2656],\n",
       "        [-0.3121],\n",
       "        [-0.2981],\n",
       "        [-0.2481],\n",
       "        [-0.2919],\n",
       "        [-0.3204],\n",
       "        [-0.3053],\n",
       "        [-0.3262],\n",
       "        [-0.3000],\n",
       "        [-0.3267],\n",
       "        [-0.3085],\n",
       "        [-0.2919],\n",
       "        [-0.2786],\n",
       "        [-0.2818],\n",
       "        [-0.3082],\n",
       "        [-0.2185],\n",
       "        [-0.3288],\n",
       "        [-0.2203],\n",
       "        [-0.3235],\n",
       "        [-0.3051],\n",
       "        [-0.2628],\n",
       "        [-0.3193],\n",
       "        [-0.2730],\n",
       "        [-0.3074],\n",
       "        [-0.2785],\n",
       "        [-0.3458],\n",
       "        [-0.2946],\n",
       "        [-0.3243],\n",
       "        [-0.3359],\n",
       "        [-0.3287],\n",
       "        [-0.2298],\n",
       "        [-0.2930],\n",
       "        [-0.3113],\n",
       "        [-0.3030],\n",
       "        [-0.3063],\n",
       "        [-0.3312],\n",
       "        [-0.3252],\n",
       "        [-0.3412],\n",
       "        [-0.3112],\n",
       "        [-0.3178],\n",
       "        [-0.3293],\n",
       "        [-0.3286],\n",
       "        [-0.1981],\n",
       "        [-0.3280],\n",
       "        [-0.3236],\n",
       "        [-0.2941],\n",
       "        [-0.3080],\n",
       "        [-0.3004],\n",
       "        [-0.3049],\n",
       "        [-0.3235],\n",
       "        [-0.3000],\n",
       "        [-0.2391],\n",
       "        [-0.3361],\n",
       "        [-0.3275],\n",
       "        [-0.2990],\n",
       "        [-0.2790],\n",
       "        [-0.3667],\n",
       "        [-0.3455],\n",
       "        [-0.3540],\n",
       "        [-0.3397],\n",
       "        [-0.2233],\n",
       "        [-0.3004],\n",
       "        [-0.2623],\n",
       "        [-0.3386],\n",
       "        [-0.3329],\n",
       "        [-0.2450],\n",
       "        [-0.2986],\n",
       "        [-0.3347],\n",
       "        [-0.2444],\n",
       "        [-0.2649],\n",
       "        [-0.2515],\n",
       "        [-0.3237],\n",
       "        [-0.3203],\n",
       "        [-0.3194],\n",
       "        [-0.2025],\n",
       "        [-0.2756],\n",
       "        [-0.3274],\n",
       "        [-0.3174],\n",
       "        [-0.3069],\n",
       "        [-0.2965],\n",
       "        [-0.3717],\n",
       "        [-0.3186],\n",
       "        [-0.3041],\n",
       "        [-0.3319],\n",
       "        [-0.3351],\n",
       "        [-0.3186],\n",
       "        [-0.3162],\n",
       "        [-0.2870],\n",
       "        [-0.3245],\n",
       "        [-0.2886],\n",
       "        [-0.2852],\n",
       "        [-0.2603],\n",
       "        [-0.3324],\n",
       "        [-0.3093],\n",
       "        [-0.2981],\n",
       "        [-0.3283],\n",
       "        [-0.3327],\n",
       "        [-0.3363],\n",
       "        [-0.2643],\n",
       "        [-0.3000],\n",
       "        [-0.2582],\n",
       "        [-0.2826],\n",
       "        [-0.3309],\n",
       "        [-0.3175],\n",
       "        [-0.2978],\n",
       "        [-0.2670],\n",
       "        [-0.2753],\n",
       "        [-0.3133],\n",
       "        [-0.3458],\n",
       "        [-0.2927],\n",
       "        [-0.2990],\n",
       "        [-0.3027],\n",
       "        [-0.3200],\n",
       "        [-0.3304],\n",
       "        [-0.3310],\n",
       "        [-0.3111],\n",
       "        [-0.2522],\n",
       "        [-0.3454],\n",
       "        [-0.3256],\n",
       "        [-0.2582],\n",
       "        [-0.3045],\n",
       "        [-0.2993],\n",
       "        [-0.3243],\n",
       "        [-0.3010],\n",
       "        [-0.2931],\n",
       "        [-0.2549],\n",
       "        [-0.3082],\n",
       "        [-0.2865],\n",
       "        [-0.3129],\n",
       "        [-0.3158],\n",
       "        [-0.3336],\n",
       "        [-0.2802],\n",
       "        [-0.3296],\n",
       "        [-0.2560],\n",
       "        [-0.3178],\n",
       "        [-0.3389],\n",
       "        [-0.3207],\n",
       "        [-0.2741],\n",
       "        [-0.3151],\n",
       "        [-0.3283],\n",
       "        [-0.3349],\n",
       "        [-0.3408],\n",
       "        [-0.2947],\n",
       "        [-0.3300],\n",
       "        [-0.3124],\n",
       "        [-0.2840],\n",
       "        [-0.2747],\n",
       "        [-0.2490]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = torch.LongTensor(y_train.values)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_tensor[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Download dataset from github\n",
    "def download_file(url):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                f.write(chunk)\n",
    "    return local_filename\n",
    "\n",
    "file_url = 'https://raw.githubusercontent.com/xinxiewu/datasets/main/pima_indians_diabetes.csv'\n",
    "df = pd.read_csv(download_file(file_url))\n",
    "\n",
    "# Diabetes Group\n",
    "df.loc[(df['diabetes'] == 1) & (df['glucose'] == 0), 'glucose'] = 140\n",
    "df.loc[(df['diabetes'] == 1) & (df['bp'] == 0), 'bp'] = 74\n",
    "df.loc[(df['diabetes'] == 1) & (df['skin_thick'] == 0), 'skin_thick'] = 27\n",
    "df.loc[(df['diabetes'] == 1) & (df['insulin'] == 0), 'insulin'] = 100\n",
    "df.loc[(df['diabetes'] == 1) & (df['bmi'] == 0), 'bmi'] = 34.25\n",
    "df.loc[(df['diabetes'] == 1) & (df['pedigree'] == 0), 'pedigree'] = 0.449\n",
    "# Non-Diabetes Group\n",
    "df.loc[(df['diabetes'] == 0) & (df['glucose'] == 0), 'glucose'] = 107\n",
    "df.loc[(df['diabetes'] == 0) & (df['bp'] == 0), 'bp'] = 70\n",
    "df.loc[(df['diabetes'] == 0) & (df['skin_thick'] == 0), 'skin_thick'] = 21\n",
    "df.loc[(df['diabetes'] == 0) & (df['insulin'] == 0), 'insulin'] = 68.792\n",
    "df.loc[(df['diabetes'] == 0) & (df['bmi'] == 0), 'bmi'] = 30.05\n",
    "df.loc[(df['diabetes'] == 0) & (df['pedigree'] == 0), 'pedigree'] = 0.336\n",
    "\n",
    "# Normalization\n",
    "df.preg = (df.preg - df.preg.mean())/df.preg.std()\n",
    "df.glucose = (df.glucose - df.glucose.mean())/df.glucose.std()\n",
    "df.bp = (df.bp - df.bp.mean())/df.bp.std()\n",
    "df.skin_thick = (df.skin_thick - df.skin_thick.mean())/df.skin_thick.std()\n",
    "df.insulin = (df.insulin - df.insulin.mean())/df.insulin.std()\n",
    "df.bmi = (df.bmi - df.bmi.mean())/df.bmi.std()\n",
    "df.pedigree = (df.pedigree - df.pedigree.mean())/df.pedigree.std()\n",
    "df.age = (df.age - df.age.mean())/df.age.std()\n",
    "\n",
    "# 7:3 Data Split\n",
    "x = df.iloc[:, 0:8]\n",
    "y = df.iloc[:, 8:9]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
